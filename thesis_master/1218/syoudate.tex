\documentclass[]{jarticle}          % 一段組
%\documentclass[twocolumn]{jarticle} % 二段組

\textwidth 180mm
\textheight 255mm
\oddsidemargin -12mm
\topmargin -15mm
\columnsep 10mm

%\vspace{0.5cm} % 一段組の場合はコメントアウトした方が体裁がよいx
%] % 一段組の場合はコメントアウトする

\usepackage{styles/labheadings}
\usepackage[dvipdfmx]{graphicx,color}
\usepackage{amsmath,amssymb}
\usepackage{url}
% 追加
\usepackage[hang,small,bf]{caption}
\usepackage[subrefformat=parens]{subcaption}
\usepackage{float}
\captionsetup{compatibility=false}

\input{numerical_definition.tex}
% report.texと同じディレクトリにnumerical_definition.texを入れておけば上の書き方でもいいはずです

\usepackage[
  dvipdfm,
  bookmarks=true,
  bookmarksnumbered=true,
  colorlinks=true]{hyperref}
\AtBeginDvi{\special{pdf:tounicode EUC-UCS2}}

\pagestyle{labheadings}
\headerleft{ワイヤーフレームと全方位画像による簡易モデルを用いた屋内環境での自己位置推定}   % ヘッダの左側のタイトル
\headerright{2025年12月18日}  % ヘッダの右側のタイトル

\begin{document}

%\twocolumn % 一段組の場合はコメントアウトする

\vspace*{2ex}
\begin{center}
 {\Large \bf 自己位置推定結果の補完手法}\\ % タイトル
 \vspace*{5mm}
 {\large M2 田川幸汰}% 発表者名
\end{center}

%\vspace{0.5cm} % 一段組の場合はコメントアウトした方が体裁がよいx
%] % 一段組の場合はコメントアウトする

%新しく作成したコマンド
% \newcommand{\reffig}[1]{\hyperref[#1]{図\ref{#1}}}
% \newcommand{\refeq}[1]{\hyperref[#1]{式(\ref{#1})}}
% \newcommand{\reftab}[1]{\hyperref[#1]{表\ref{#1}}}
% \newcommand{\refsec}[1]{\hyperref[#1]{\ref{#1}章}}
% \newcommand{\refsubsec}[1]{\hyperref[#1]{\ref{#1}節}}

% 数式
%\begin{equation}
%  数式記述  
%  \label{ラベル名}
%\end{equation}

% 図
% \begin{figure}[!ht]
%   \begin{center}
%     \includegraphics[scale=0.5]{figures/画像ファイル名}
%     \caption{キャプション名}
%     \label{ラベル名}
%   \end{center}
% \end{figure}

% リスト
% \begin{enumerate or itemize}
%   \item 
% \end{enumerate or itemize}
\section{自己位置推定結果の補完}
実際のカメラ入力を用いたリアルタイム動作では、特徴点マッチング処理による遅延により推定位置が端末の実際の位置と乖離する可能性がある。
さらに、屋内環境においては常に十分な特徴量が得られるとは限らず、マッチングが不安定となり自己位置が更新されない場合も想定される。
このような課題に対して、より安定した自己位置推定を実現し、実用的なAR道案内システムを構築するため、本研究ではセンサ情報との併用を検討した。
具体的には、Appleが提供するARフレームワークであるARKitが有するVisual Inertial Odometry（VIO）を併用し、推定結果の補完を図る。

\subsection{Visual Inertial Odometry}
ARKit では、カメラ画像に含まれる視覚情報と、デバイスの慣性センサーによるモーション情報を統合した 
Visual-Inertial Odometry (VIO) によって、デバイスの位置および姿勢を推定する。
これにより、特徴点マッチングのみに依存した手法に比べて、特徴点が乏しい環境や動きが速い状況においても安定したトラッキングが可能となる。

\subsection{ARKitのカメラ変換行列}
ここで、各フレームのデバイスの姿勢は、カメラ変換行列(ARFrame.camera.transform)で表される。
この変換行列はカメラ座標系から、ARKit座標系の変換を表す
$4\times{4}$の同次変換行列であり，次のように書ける：
\begin{equation}
\mathbf{T}_{\mathrm{cam}\rightarrow\mathrm{AR}} =
\begin{bmatrix}
\mathbf{R}_{\mathrm{cam}\rightarrow\mathrm{AR}} & \mathbf{t}_{\mathrm{cam}\rightarrow\mathrm{AR}} \\
\mathbf{0}^\mathrm{T} & 1
\end{bmatrix}
\end{equation}
ここで，
$\mathbf{R}_{\mathrm{cam}\rightarrow\mathrm{AR}}$は
カメラ座標系から ARKit 世界座標系への回転行列，
$\mathbf{t}_{\mathrm{cam}\rightarrow\mathrm{AR}}$ は
ARKit世界座標系におけるカメラ原点位置を表す並進ベクトルである。

ARKit座標系は、ARKitのセッション開始時に呼び出される座標系で、
初期状態では重力と反対方向をY軸、カメラの向いている方向をZ軸とし、Y軸とZ軸の外積がX軸として固定される。
なお、地磁気センサを基に、北向きをZ軸として固定することもできる。
ここでユーザーが定義する世界座標系を含めた各座標系の関係を図\ref{one}に示す。
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.7\textwidth]{figures/fig1.png}
    \caption{座標系の関係}
    \label{one}
  \end{center}
\end{figure}
ここで、注意が必要なのは、カメラ座標系の軸の符号が異なることである。OpenCVのカメラ座標系がX右、Y下、Z奥が正の向きであるのに対して、
ARKitのカメラ座標はX右、Y上、Z手前が正の向きとなる(図\ref{two})
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.3\textwidth]{figures/fig2.png}
    \caption{ARKitカメラ座標の定義}
    \label{two}
  \end{center}
\end{figure}
ここで示した座標系の違いを考慮して、自己位置推定結果の補正を行う必要がある。

\subsection{補完の方針}
カメラ画像に基づく推定結果はフレーム毎に得られるわけではなく、
時々更新されるのみである。一方ARKitによる自己位置推定は高頻度で
得られるため、ARKitによるカメラ位置姿勢により、自己位置を更新する。
本手法における補完処理の方針を以下に示す。
\begin{enumerate}
  \item 画像取得時点の\texttt{ARFrame.camera.transform}より、
  カメラ座標系$\rightarrow$ARKit座標系の変換行列
  （$\mathbf{R}_{\mathrm{cam} \rightarrow \mathrm{AR}}, \mathbf{t}_{\mathrm{cam} \rightarrow \mathrm{AR}}$）
  を取得する。
  \item 画像の特徴点マッチングにより推定された、世界座標系$\rightarrow$カメラ座標系への変換行列
  （$\mathbf{R}_{\mathrm{world}\rightarrow\mathrm{cam}}, \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{cam}}$）
  を取得する。
  \item 上記1, 2の結果より、ARKit座標系$\rightarrow$世界座標系の変換行列
  （$\mathbf{R}_{\mathrm{ar} \rightarrow \mathrm{world}}, \mathbf{t}_{\mathrm{ar} \rightarrow \mathrm{world}}$）
  を計算する。ARKit座標系と世界座標系との対応関係は、カメラ位置が更新されても不変である。
  \item フレーム更新時：ARKitが毎フレーム提供するカメラ姿勢
  （$\mathbf{t}_{\mathrm{cam}\rightarrow\mathrm{AR}}$）
  を取得し、3で求めた変換行列を適用することで世界座標系におけるカメラ位置を推定する。
\end{enumerate}

\subsection{変換行列の計算}
ARKit座標系$\rightarrow$世界座標系の変換行列
（$\mathbf{R}_{\mathrm{ar} \rightarrow \mathrm{world}}, \mathbf{t}_{\mathrm{ar} \rightarrow \mathrm{world}}$）
の計算方法を以下に示す。

カメラ座標系$\rightarrow$ARKit座標系の変換は以下の式\ref{eq:one}で表される。
\begin{equation}
  \mathbf{X}_{\mathrm{ar}}
  =
  \mathbf{R}_{\mathrm{cam1}\rightarrow\mathrm{ar}}
  \mathbf{X}_{\mathrm{cam1}}
  +
  \mathbf{t}_{\mathrm{cam1}\rightarrow\mathrm{ar}}
  \label{eq:one}
\end{equation}

また、世界座標系$\rightarrow$カメラ座標系の変換は以下の式\ref{eq:two}で表される。
\begin{equation}
  \mathbf{X}_{\mathrm{cam2}}
  =
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{cam2}}
  \mathbf{X}_{\mathrm{world}}
  +
  \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{cam2}}
  \label{eq:two}
\end{equation}

さらに、ARKitのカメラ座標系$\mathbf{X}_{\mathrm{cam1}}$と世界座標系のカメラ座標系$\mathbf{X}_{\mathrm{cam2}}$の座標系の違いは
以下の式\ref{eq:three}で表される
\begin{align}
  \mathbf{X}_{\mathrm{cam2}}
  = \mathbf{S}\,\mathbf{X}_{\mathrm{cam1}}
  \\
  \mathbf{S}
  =
  \begin{bmatrix}
  1 & 0 & 0 \\
  0 & -1 & 0 \\
  0 & 0 & -1
  \end{bmatrix}
  \label{eq:three}
\end{align}

式\ref{eq:one}、式\ref{eq:two}、式\ref{eq:three}から、
世界座標系$\rightarrow$ARKit座標系の変換は以下の式\ref{eq:four}で整理される。
\begin{align}
  \mathbf{X}_{\mathrm{ar}}
  &=
  \mathbf{R}_{\mathrm{cam}\rightarrow\mathrm{ar}}(\mathbf{S}(
    \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{cam2}}
    \mathbf{X}_{\mathrm{world}}
    +
    \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{cam2}}
  ))
  +
  \mathbf{t}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  \\
  \mathbf{X}_{\mathrm{ar}}
  &=
  (\mathbf{R}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  \mathbf{S}
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{cam2}})
  \mathbf{X}_{\mathrm{world}}
  +
  \mathbf{R}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  \mathbf{S}
  \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{cam2}}
  +
  \mathbf{t}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  \\
  \mathbf{X}_{\mathrm{ar}}
  &=
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{ar}}\mathbf{X}_{\mathrm{world}}
  +
  \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{ar}}
\end{align}

\begin{align}
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{ar}}
  &=
  \mathbf{R}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  \mathbf{S}
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{cam2}}
  \\
  \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{ar}}
  &=
  \mathbf{R}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  \mathbf{S}
  \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{cam2}}
  +
  \mathbf{t}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  \label{eq:four}
\end{align}

式\ref{eq:four}より、世界座標系とARKit座標系の座標変換は式\ref{eq:five}で表される。
\begin{align}
  \mathbf{X}_{\mathrm{world}}
  &=
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{ar}}^{\top}
  \mathbf{X}_{\mathrm{ar}}
  -
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{ar}}^{\top}
  \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{ar}}
  \\
  \mathbf{X}_{\mathrm{world}}
  &=
  \mathbf{R}_{\mathrm{ar}\rightarrow\mathrm{world}}\mathbf{X}_{\mathrm{ar}}
  +
  \mathbf{t}_{\mathrm{ar}\rightarrow\mathrm{world}}
\end{align}

\begin{align}
  \mathbf{R}_{\mathrm{ar}\rightarrow\mathrm{world}}
  &=
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{ar}}^{\top}
  \\
  &=
  (\mathbf{R}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  \mathbf{S}
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{cam}}
  )^{\top}
  \\
  \mathbf{t}_{\mathrm{ar}\rightarrow\mathrm{world}}
  &=
  -
  \mathbf{R}_{\mathrm{world}\rightarrow\mathrm{ar}}^{\top}
  \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{ar}}
  \\
  &=
  -
  \mathbf{R}_{\mathrm{ar}\rightarrow\mathrm{world}}
  (
  \mathbf{R}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  \mathbf{S}
  \mathbf{t}_{\mathrm{world}\rightarrow\mathrm{cam}}
  +
  \mathbf{t}_{\mathrm{cam}\rightarrow\mathrm{ar}}
  )
  \label{eq:five}
\end{align}

\end{document}
