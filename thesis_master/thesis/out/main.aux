\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\HyPL@Entry{2<</P(0)>>}
\citation{IDC_DT_Survey2024}
\citation{GlobalGrowthInsights_DT}
\citation{ORB_SLAM}
\citation{Cadena2016}
\HyPL@Entry{3<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {第1章}はじめに}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:chapter}{{1}{1}{はじめに}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}研究背景}{1}{section.1.1}\protected@file@percent }
\newlabel{sec:background}{{1.1}{1}{研究背景}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}研究目的}{1}{section.1.2}\protected@file@percent }
\newlabel{sec:purpose}{{1.2}{1}{研究目的}{section.1.2}{}}
\citation{ORB_SLAM}
\citation{ORB_SLAM2}
\citation{CNN_SLAM}
\citation{ORB_SLAM}
\citation{Cadena2016}
\citation{ImageLocalizationSfM}
\citation{ImageRetrievalLocalization}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}関連研究}{2}{section.1.3}\protected@file@percent }
\newlabel{sec:related}{{1.3}{2}{関連研究}{section.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Visual SLAM による自己位置推定}{2}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}画像ベースの自己位置推定手法}{2}{subsection.1.3.2}\protected@file@percent }
\citation{Sattler2011}
\citation{Schindler2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}簡易3次元モデルを用いた位置推定}{3}{subsection.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}本論文の構成}{3}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第2章}簡易3次元モデルの生成}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}簡易3次元モデル生成の方針}{4}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 異なる3次元モデル表現の比較. 従来の点群(a)やメッシュ(b)と比較し、本研究(c)では構造を大幅に簡略化している。\relax }}{4}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{two:one}{{2.1}{4}{異なる3次元モデル表現の比較. 従来の点群(a)やメッシュ(b)と比較し、本研究(c)では構造を大幅に簡略化している。\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}座標系の定義}{4}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}カメラ座標系}{4}{subsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces 世界座標系とカメラ座標系、画像座標系の関係\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{two:two}{{2.2}{5}{世界座標系とカメラ座標系、画像座標系の関係\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}画像座標系}{5}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}カメラ内部パラメータの設定}{5}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}ワイヤーフレーム生成の方針}{6}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}2次元マップと3次元空間の対応付け}{6}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}アフィン変換による写像}{7}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}非線形な歪みへの対応}{7}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}頂点列の回転方向の判定と統一}{7}{subsection.2.4.3}\protected@file@percent }
\newlabel{clockwise}{{2.4.3}{7}{頂点列の回転方向の判定と統一}{subsection.2.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}カメラ位置に基づく床境界点の最適化}{8}{section.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces 床境界点の追加方法。 (a)カメラ位置を床境界辺に射影する。(b)射影点間が広い場合は各点から内側に個別に頂点を追加する。(c)射影点間が狭い場合は各点の中点に頂点を追加する。\relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{two:three}{{2.3}{8}{床境界点の追加方法。\\(a)カメラ位置を床境界辺に射影する。(b)射影点間が広い場合は各点から内側に個別に頂点を追加する。(c)射影点間が狭い場合は各点の中点に頂点を追加する。\relax }{figure.caption.5}{}}
\citation{Shewchuk1996Triangle}
\@writefile{toc}{\contentsline {paragraph}{射影点の間隔が大きい場合}{9}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{射影点の間隔が小さい場合}{9}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}床面および壁面の幾何構造}{9}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}床面のメッシュ化}{10}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}壁面のメッシュ化}{10}{subsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}UV座標の定義}{10}{subsection.2.6.3}\protected@file@percent }
\newlabel{UV}{{2.6.3}{10}{UV座標の定義}{subsection.2.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}全方位画像を用いたテクスチャ取得の方針}{11}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.8}透視投影画像変換}{11}{section.2.8}\protected@file@percent }
\citation{Sugaya2024}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}透視投影画像を用いた全方位カメラの位置姿勢推定}{12}{section.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.10}メッシュの座標系変換と投影}{13}{section.2.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.11}テクスチャ画像の形状変換}{15}{section.2.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.12}テクスチャの視覚的品質の改善}{15}{section.2.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.12.1}カメラとメッシュの相対位置関係の導出}{16}{subsection.2.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.12.2}テクスチャのブレンド処理}{16}{subsection.2.12.2}\protected@file@percent }
\newlabel{eq:blend_func}{{2.45}{16}{テクスチャのブレンド処理}{equation.2.12.45}{}}
\newlabel{eq:sigmoid_weight}{{2.46}{17}{テクスチャのブレンド処理}{equation.2.12.46}{}}
\citation{Lowe2004}
\citation{Alcantarilla2013}
\@writefile{toc}{\contentsline {chapter}{\numberline {第3章}特徴点マッチングに基づく自己位置推定}{18}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}特徴点検出およびマッチングの概要}{18}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}従来手法による特徴点マッチング}{18}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}特徴点検出}{18}{subsection.3.2.1}\protected@file@percent }
\citation{DeTone2018SuperPoint}
\citation{DeTone2018SuperPoint}
\citation{DeTone2018SuperPoint}
\citation{Sarlin2020SuperGlue}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}特徴点マッチング}{19}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}マッチングの精度向上}{19}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}学習ベース手法による特徴点マッチング}{19}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}特徴点検出}{19}{subsection.3.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces SuperPointのアーキテクチャ. 出典：DeTone et al.(2018)\cite  {DeTone2018SuperPoint} Fig.\nobreakspace  {}1\relax }}{19}{figure.caption.13}\protected@file@percent }
\newlabel{three:one}{{3.1}{19}{SuperPointのアーキテクチャ. 出典：DeTone et al.(2018)\cite {DeTone2018SuperPoint} Fig.~1\relax }{figure.caption.13}{}}
\citation{Sarlin2020SuperGlue}
\citation{Sarlin2020SuperGlue}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}特徴点マッチング}{20}{subsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces SuperGlueのアーキテクチャ. 出典：Sarlin et al.(2020)\cite  {Sarlin2020SuperGlue} Fig.\nobreakspace  {}3\relax }}{20}{figure.caption.14}\protected@file@percent }
\newlabel{three:two}{{3.2}{20}{SuperGlueのアーキテクチャ. 出典：Sarlin et al.(2020)\cite {Sarlin2020SuperGlue} Fig.~3\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}マッチングの精度向上}{20}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}テクスチャ画像座標から世界座標への変換}{20}{section.3.4}\protected@file@percent }
\citation{matsushita2024}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}自己位置推定}{21}{section.3.5}\protected@file@percent }
\citation{AppleARKitTracking}
\citation{AppleARKitWorldTracking}
\@writefile{toc}{\contentsline {chapter}{\numberline {第4章}自己位置推定結果を用いた屋内ナビゲーション}{23}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}屋内ナビゲーションの方針}{23}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}簡易モデルによる自己位置推定の課題}{23}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}提案手法に基づく屋内ナビゲーションの基本方針}{23}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Visual-Inertial Odometry (VIO) による自己位置推定}{23}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}ARKitの座標系の定義}{24}{subsection.4.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces 世界座標系とARKitカメラ座標系、AR座標系の関係\relax }}{24}{figure.caption.15}\protected@file@percent }
\newlabel{four:one}{{4.1}{24}{世界座標系とARKitカメラ座標系、AR座標系の関係\relax }{figure.caption.15}{}}
\newlabel{eq:camtransform}{{4.1}{24}{ARKitの座標系の定義}{equation.4.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}自己位置推定手法の比較検討方針}{24}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}屋内ナビゲーションシステムの構成}{25}{section.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces 屋内ナビゲーションシステムの構成\relax }}{26}{figure.caption.16}\protected@file@percent }
\newlabel{four:three}{{4.2}{26}{屋内ナビゲーションシステムの構成\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}目的地設定}{26}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}カメラ画像取得および端末とPC間の通信}{26}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}自己位置推定結果の受信および座標系の更新}{27}{subsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}世界座標系とAR座標系の相互変換}{27}{subsection.4.3.4}\protected@file@percent }
\newlabel{eq:one}{{4.3}{27}{世界座標系とAR座標系の相互変換}{equation.4.3.3}{}}
\newlabel{eq:two}{{4.4}{27}{世界座標系とAR座標系の相互変換}{equation.4.3.4}{}}
\newlabel{eq:four}{{4.9}{28}{世界座標系とAR座標系の相互変換}{equation.4.3.9}{}}
\newlabel{eq:five}{{4.13}{28}{世界座標系とAR座標系の相互変換}{equation.4.3.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}目的地および進行方向オブジェクトの描画}{28}{subsection.4.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第5章}実験}{29}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}実験準備}{29}{section.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces 実験で使用した機材および実行環境\relax }}{29}{table.caption.17}\protected@file@percent }
\newlabel{five:one}{{5.1}{29}{実験で使用した機材および実行環境\relax }{table.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces 全方位画像の撮影位置\relax }}{30}{figure.caption.18}\protected@file@percent }
\newlabel{five:two}{{5.1}{30}{全方位画像の撮影位置\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces 全方位画像(10番)と前後の透視投影画像\relax }}{30}{figure.caption.19}\protected@file@percent }
\newlabel{five:three}{{5.2}{30}{全方位画像(10番)と前後の透視投影画像\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}簡易モデル生成}{30}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}データセットおよびパラメータ設定}{30}{subsection.5.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces ワイヤーフレームの床面の境界点\relax }}{31}{figure.caption.20}\protected@file@percent }
\newlabel{five:four}{{5.3}{31}{ワイヤーフレームの床面の境界点\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}ワイヤーフレーム生成結果}{31}{subsection.5.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces ワイヤーフレームモデル（サンプリング間隔：左から 4\,m, 3\,m, 2\,m）\relax }}{31}{figure.caption.21}\protected@file@percent }
\newlabel{five:five}{{5.4}{31}{ワイヤーフレームモデル（サンプリング間隔：左から 4\,m, 3\,m, 2\,m）\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}テクスチャ割り当て結果}{32}{subsection.5.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces テクスチャを割り当てた簡易モデルの全体図\relax }}{32}{figure.caption.22}\protected@file@percent }
\newlabel{five:six}{{5.5}{32}{テクスチャを割り当てた簡易モデルの全体図\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces 簡易モデルの拡大図（サンプリング間隔：左から 4\,m, 3\,m, 2\,m）\relax }}{32}{figure.caption.23}\protected@file@percent }
\newlabel{five:seven}{{5.6}{32}{簡易モデルの拡大図（サンプリング間隔：左から 4\,m, 3\,m, 2\,m）\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}特徴点マッチング手法の比較実験}{32}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}実験条件}{32}{subsection.5.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces 歩行経路と入力画像\relax }}{33}{figure.caption.24}\protected@file@percent }
\newlabel{five:input}{{5.7}{33}{歩行経路と入力画像\relax }{figure.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces 従来手法（SIFT, AKAZE）のパラメータ設定\relax }}{33}{table.caption.25}\protected@file@percent }
\newlabel{five:eight}{{5.2}{33}{従来手法（SIFT, AKAZE）のパラメータ設定\relax }{table.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces 深層学習手法（SuperPoint, SuperGlue）のパラメータ設定\relax }}{33}{table.caption.26}\protected@file@percent }
\newlabel{five:nine}{{5.3}{33}{深層学習手法（SuperPoint, SuperGlue）のパラメータ設定\relax }{table.caption.26}{}}
\citation{magsac}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}実験結果}{34}{subsection.5.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces 特徴点マッチング結果の比較 上段から SIFT、AKAZE、SuperPoint+SuperGlue を示し、画像内左はテクスチャ画像、右は入力画像である。\relax }}{35}{figure.caption.27}\protected@file@percent }
\newlabel{five:ten}{{5.8}{35}{特徴点マッチング結果の比較\\上段から SIFT、AKAZE、SuperPoint+SuperGlue を示し、画像内左はテクスチャ画像、右は入力画像である。\relax }{figure.caption.27}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces 各手法におけるマッチング成功枚数と平均処理時間\relax }}{36}{table.caption.28}\protected@file@percent }
\newlabel{five:eleven}{{5.4}{36}{各手法におけるマッチング成功枚数と平均処理時間\relax }{table.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}特徴点マッチングに基づく自己位置推定結果の評価}{36}{section.5.4}\protected@file@percent }
\newlabel{localization}{{5.4}{36}{特徴点マッチングに基づく自己位置推定結果の評価}{section.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces 自己位置推定結果（サンプリング間隔：左から 4\,m, 3\,m, 2\,m）\relax }}{36}{figure.caption.29}\protected@file@percent }
\newlabel{five:twelve}{{5.9}{36}{自己位置推定結果（サンプリング間隔：左から 4\,m, 3\,m, 2\,m）\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces 自己位置推定に失敗したケース\relax }}{37}{figure.caption.31}\protected@file@percent }
\newlabel{five:fourteen}{{5.10}{37}{自己位置推定に失敗したケース\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}屋内ナビゲーションにおける自己位置推定結果の比較}{37}{section.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}実験条件}{37}{subsection.5.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}実験結果}{38}{subsection.5.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces 自己位置推定軌跡の比較\relax }}{38}{figure.caption.32}\protected@file@percent }
\newlabel{five:thirteen}{{5.11}{38}{自己位置推定軌跡の比較\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}アプリケーションの実行の様子}{39}{subsection.5.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces 屋内アプリケーションの実行画面\relax }}{40}{figure.caption.36}\protected@file@percent }
\newlabel{five:fifteen}{{5.12}{40}{屋内アプリケーションの実行画面\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {第6章}まとめ}{41}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}本研究の成果}{41}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}今後の展望}{41}{section.6.2}\protected@file@percent }
\bibcite{IDC_DT_Survey2024}{1}
\bibcite{GlobalGrowthInsights_DT}{2}
\bibcite{ORB_SLAM}{3}
\bibcite{ORB_SLAM2}{4}
\bibcite{CNN_SLAM}{5}
\bibcite{Cadena2016}{6}
\bibcite{ImageLocalizationSfM}{7}
\bibcite{ImageRetrievalLocalization}{8}
\bibcite{IndoorSurvey}{9}
\bibcite{IndoorLiDARNav}{10}
\bibcite{2DMapLocalization}{11}
\bibcite{SimplifiedModelLocalization}{12}
\bibcite{Schindler2007}{13}
\bibcite{Sattler2011}{14}
\bibcite{Shewchuk1996Triangle}{15}
\bibcite{Sugaya2024}{16}
\bibcite{Lowe2004}{17}
\bibcite{Alcantarilla2013}{18}
\bibcite{DeTone2018SuperPoint}{19}
\bibcite{Sarlin2020SuperGlue}{20}
\bibcite{matsushita2024}{21}
\bibcite{AppleARKitTracking}{22}
\bibcite{AppleARKitWorldTracking}{23}
\bibcite{magsac}{24}
\gdef \@abspage@last{47}
