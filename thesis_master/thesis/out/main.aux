\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</P(0)>>}
\citation{IDC_DT_Survey2024}
\citation{GlobalGrowthInsights_DT}
\citation{ORB_SLAM}
\citation{Cadena2016}
\HyPL@Entry{1<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {第1章}はじめに}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:chapter}{{1}{1}{はじめに}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}研究背景}{1}{section.1.1}\protected@file@percent }
\newlabel{sec:background}{{1.1}{1}{研究背景}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}研究目的}{1}{section.1.2}\protected@file@percent }
\newlabel{sec:purpose}{{1.2}{1}{研究目的}{section.1.2}{}}
\citation{ORB_SLAM}
\citation{ORB_SLAM2}
\citation{CNN_SLAM}
\citation{ORB_SLAM}
\citation{Cadena2016}
\citation{RobustWeakTextureSLAM}
\citation{Sarlin2020SuperGlue}
\citation{Sarlin2020SuperGlue}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}関連研究}{2}{section.1.3}\protected@file@percent }
\newlabel{sec:related}{{1.3}{2}{関連研究}{section.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Visual SLAM による自己位置推定と三次元マッピング}{2}{subsection.1.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces 弱テクスチャ環境における自己位置推定結果および追跡特徴点の可視化. 出典：Sarlin et al.(2020)\cite  {Sarlin2020SuperGlue}, Fig.\nobreakspace  {}4\relax }}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{one:one}{{1.1}{2}{弱テクスチャ環境における自己位置推定結果および追跡特徴点の可視化. 出典：Sarlin et al.(2020)\cite {Sarlin2020SuperGlue}, Fig.~4\relax }{figure.caption.1}{}}
\citation{ImageLocalizationSfM}
\citation{ImageRetrievalLocalization}
\citation{Schindler2007}
\citation{Sattler2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}画像ベースの自己位置推定手法}{3}{subsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}簡易3次元モデルを用いた位置推定}{3}{subsection.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}本論文の構成}{4}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第2章}簡易モデルを構成するワイヤーフレームの生成}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}ワイヤーフレーム生成の方針}{5}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 異なる3次元モデル表現の比較（左：点群モデル, 中央：フォトグラメトリモデル, 右：本研究で用いる簡易モデル）\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{two:one}{{2.1}{5}{異なる3次元モデル表現の比較（左：点群モデル, 中央：フォトグラメトリモデル, 右：本研究で用いる簡易モデル）\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}入力情報と前提条件}{5}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}2次元マップと3次元空間の対応付け}{6}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}床境界における観測点に基づくサンプリング}{6}{section.2.3}\protected@file@percent }
\citation{Shewchuk1996Triangle}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}床面および壁面の幾何構造}{7}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第3章}簡易モデルへのテクスチャ割り当て}{8}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}全方位画像から透視投影画像生成}{8}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}全方位画像を用いたテクスチャ取得の方針}{8}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}透視投影画像変換}{8}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}座標系の定義}{9}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}カメラ座標系}{9}{subsection.3.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces 世界座標系とカメラ座標系、画像座標系の関係\relax }}{9}{figure.caption.3}\protected@file@percent }
\newlabel{three:one}{{3.1}{9}{世界座標系とカメラ座標系、画像座標系の関係\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}画像座標系}{9}{subsection.3.2.2}\protected@file@percent }
\citation{sugaya2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}カメラ内部パラメータの設定}{10}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}複数の透視投影カメラによる全方位カメラ位置姿勢推定}{10}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}座標系変換と投影}{11}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}テクスチャ候補の評価}{11}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}テクスチャの射影変換}{12}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}テクスチャの視覚的品質の改善}{12}{section.3.5}\protected@file@percent }
\citation{Lowe2004}
\citation{Alcantarilla2013}
\@writefile{toc}{\contentsline {chapter}{\numberline {第4章}入力画像とテクスチャの特徴点マッチング}{13}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}特徴点検出およびマッチングの概要}{13}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}従来手法による特徴点マッチング}{13}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}特徴点検出}{13}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}特徴点マッチング}{13}{subsection.4.2.2}\protected@file@percent }
\citation{DeTone2018SuperPoint}
\citation{DeTone2018SuperPoint}
\citation{DeTone2018SuperPoint}
\citation{Sarlin2020SuperGlue}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}マッチングの精度向上}{14}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}学習ベース手法による特徴点マッチング}{14}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}特徴点検出}{14}{subsection.4.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces SuperPointのアーキテクチャ. 出典：DeTone et al.(2018)\cite  {DeTone2018SuperPoint} Fig.\nobreakspace  {}1\relax }}{14}{figure.caption.4}\protected@file@percent }
\newlabel{four:one}{{4.1}{14}{SuperPointのアーキテクチャ. 出典：DeTone et al.(2018)\cite {DeTone2018SuperPoint} Fig.~1\relax }{figure.caption.4}{}}
\citation{Sarlin2020SuperGlue}
\citation{Sarlin2020SuperGlue}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}特徴点マッチング}{15}{subsection.4.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces SuperGlueのアーキテクチャ. 出典：Sarlin et al.(2020)\cite  {Sarlin2020SuperGlue} Fig.\nobreakspace  {}3\relax }}{15}{figure.caption.5}\protected@file@percent }
\newlabel{four:two}{{4.2}{15}{SuperGlueのアーキテクチャ. 出典：Sarlin et al.(2020)\cite {Sarlin2020SuperGlue} Fig.~3\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}マッチングの精度向上}{15}{subsection.4.3.3}\protected@file@percent }
\citation{matsushita2024}
\@writefile{toc}{\contentsline {chapter}{\numberline {第5章}特徴点マッチングに基づく自己位置推定}{16}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}テクスチャ画像座標から世界座標への変換}{16}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}2次元座標から3次元座標への変換}{16}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}自己位置推定}{16}{section.5.2}\protected@file@percent }
\citation{AppleARKitTracking}
\citation{AppleARKitWorldTracking}
\@writefile{toc}{\contentsline {chapter}{\numberline {第6章}自己位置推定結果を用いた屋内ナビゲーション}{18}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}屋内ナビゲーションの方針}{18}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}簡易モデルによる自己位置推定の課題}{18}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}提案手法に基づく屋内ナビゲーションの基本方針}{18}{subsection.6.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}ARKitによる自己位置推定}{18}{subsection.6.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces 世界座標系とカメラ座標系、AR座標系の関係\relax }}{19}{figure.caption.6}\protected@file@percent }
\newlabel{six:one}{{6.1}{19}{世界座標系とカメラ座標系、AR座標系の関係\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces ARKitカメラ座標系の定義\relax }}{19}{figure.caption.7}\protected@file@percent }
\newlabel{six:two}{{6.2}{19}{ARKitカメラ座標系の定義\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}自己位置推定手法の使い分けと比較方針}{20}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}屋内ナビゲーションシステムの構成}{20}{section.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces 世界座標系とカメラ座標系、画像座標系の関係\relax }}{20}{figure.caption.8}\protected@file@percent }
\newlabel{six:three}{{6.3}{20}{世界座標系とカメラ座標系、画像座標系の関係\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}目的地設定}{21}{subsection.6.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}カメラ画像取得および端末とPC間の通信}{21}{subsection.6.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}自己位置推定結果の受信および座標系の更新}{21}{subsection.6.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}変換行列の計算}{21}{subsection.6.3.4}\protected@file@percent }
\newlabel{eq:one}{{6.2}{21}{変換行列の計算}{equation.6.3.2}{}}
\newlabel{eq:two}{{6.3}{22}{変換行列の計算}{equation.6.3.3}{}}
\newlabel{eq:three}{{6.5}{22}{変換行列の計算}{equation.6.3.5}{}}
\newlabel{eq:four}{{6.10}{22}{変換行列の計算}{equation.6.3.10}{}}
\newlabel{eq:five}{{6.16}{22}{変換行列の計算}{equation.6.3.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.5}目的地および進行方向オブジェクトの描画}{22}{subsection.6.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第7章}実験}{24}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}実験準備}{24}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}全方位カメラパラメータ推定結果}{24}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}簡易モデル生成結果}{24}{section.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.4}特徴点マッチング手法の比較評価}{24}{section.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.5}特徴点マッチングに基づく自己位置推定結果の評価}{24}{section.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.6}屋内ナビゲーションにおける自己位置推定結果の比較}{25}{section.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第8章}まとめ}{26}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}本研究の成果}{26}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}今後の展望}{26}{section.8.2}\protected@file@percent }
\bibcite{IDC_DT_Survey2024}{1}
\bibcite{GlobalGrowthInsights_DT}{2}
\bibcite{ORB_SLAM}{3}
\bibcite{ORB_SLAM2}{4}
\bibcite{CNN_SLAM}{5}
\bibcite{RobustWeakTextureSLAM}{6}
\bibcite{Cadena2016}{7}
\bibcite{ImageLocalizationSfM}{8}
\bibcite{ImageRetrievalLocalization}{9}
\bibcite{IndoorSurvey}{10}
\bibcite{IndoorLiDARNav}{11}
\bibcite{2DMapLocalization}{12}
\bibcite{SimplifiedModelLocalization}{13}
\bibcite{Schindler2007}{14}
\bibcite{Sattler2011}{15}
\bibcite{Shewchuk1996Triangle}{16}
\bibcite{Sugaya2024}{17}
\bibcite{Lowe2004}{18}
\bibcite{Alcantarilla2013}{19}
\bibcite{DeTone2018SuperPoint}{20}
\bibcite{Sarlin2020SuperGlue}{21}
\bibcite{matsushita2024}{22}
\bibcite{AppleARKitTracking}{23}
\bibcite{AppleARKitWorldTracking}{24}
\gdef \@abspage@last{30}
