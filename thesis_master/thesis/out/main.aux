\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</P(\376\377\0000)>>}
\citation{IDC_DT_Survey2024}
\citation{GlobalGrowthInsights_DT}
\citation{ORB_SLAM}
\citation{Cadena2016}
\HyPL@Entry{1<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {第1章}はじめに}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:chapter}{{1}{1}{はじめに}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}研究背景}{1}{section.1.1}\protected@file@percent }
\newlabel{sec:background}{{1.1}{1}{研究背景}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}研究目的}{1}{section.1.2}\protected@file@percent }
\newlabel{sec:purpose}{{1.2}{1}{研究目的}{section.1.2}{}}
\citation{ORB_SLAM}
\citation{ORB_SLAM2}
\citation{CNN_SLAM}
\citation{ORB_SLAM}
\citation{Cadena2016}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}関連研究}{2}{section.1.3}\protected@file@percent }
\newlabel{sec:related}{{1.3}{2}{関連研究}{section.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Visual SLAM による自己位置推定と三次元マッピング}{2}{subsection.1.3.1}\protected@file@percent }
\citation{ImageLocalizationSfM}
\citation{ImageRetrievalLocalization}
\citation{Schindler2007}
\citation{Sattler2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}画像ベースの自己位置推定手法}{3}{subsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}簡易3次元モデルを用いた位置推定}{3}{subsection.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}本論文の構成}{3}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第2章}簡易モデルを構成するワイヤーフレームの生成}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}ワイヤーフレーム生成の方針}{4}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 異なる3次元モデル表現の比較（左：点群モデル, 中央：フォトグラメトリモデル, 右：本研究で用いる簡易モデル）}}{4}{figure.2.1}\protected@file@percent }
\newlabel{one}{{2.1}{4}{異なる3次元モデル表現の比較（左：点群モデル, 中央：フォトグラメトリモデル, 右：本研究で用いる簡易モデル）}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}入力情報と前提条件}{4}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}2次元マップと3次元空間の対応付け}{5}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}床境界における観測点に基づくサンプリング}{5}{section.2.3}\protected@file@percent }
\citation{Shewchuk1996Triangle}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}床面および壁面の幾何構造}{6}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第3章}簡易モデルへのテクスチャ割り当て}{7}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}全方位画像から透視投影画像生成}{7}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}全方位画像を用いたテクスチャ取得の方針}{7}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}透視投影画像変換}{7}{subsection.3.1.2}\protected@file@percent }
\citation{sugaya2024}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}座標系の定義}{8}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}カメラ座標系}{8}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}スクリーン座標系}{8}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}カメラ内部パラメータの設定}{8}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}複数の透視投影カメラによる全方位カメラ位置姿勢推定}{9}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}座標系変換と投影}{9}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}テクスチャ候補の評価}{10}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}テクスチャの射影変換}{10}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}テクスチャの視覚的品質の改善}{11}{section.3.5}\protected@file@percent }
\citation{Lowe2004}
\citation{Alcantarilla2013}
\@writefile{toc}{\contentsline {chapter}{\numberline {第4章}入力画像とテクスチャの特徴点マッチング}{12}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}特徴点検出およびマッチングの概要}{12}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}従来手法による特徴点マッチング}{12}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}特徴点検出}{12}{subsection.4.2.1}\protected@file@percent }
\citation{DeTone2018SuperPoint}
\citation{Sarlin2020SuperGlue}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}特徴点マッチング}{13}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}マッチングの精度向上}{13}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}学習ベース手法による特徴点マッチング}{13}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}特徴点検出}{13}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}特徴点マッチング}{13}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}マッチングの精度向上}{13}{subsection.4.3.3}\protected@file@percent }
\citation{matsushita2024}
\@writefile{toc}{\contentsline {chapter}{\numberline {第5章}特徴点マッチングに基づく自己位置推定}{15}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}テクスチャ画像座標から世界座標への変換}{15}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}2次元座標から3次元座標への変換}{15}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}自己位置推定}{15}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第6章}自己位置推定結果を用いた屋内ナビゲーション}{17}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}屋内ナビゲーションにおける自己位置推定の課題}{17}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}提案手法に基づくナビゲーションの基本方針}{17}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}モバイル端末の自己位置推定機能による補完}{17}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}自己位置推定手法の使い分けと比較方針}{17}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}屋内ナビゲーションシステムの構成}{18}{section.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}目的地設定}{18}{subsection.6.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.2}端末とPC間の通信}{18}{subsection.6.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.3}端末の自己位置の更新}{18}{subsection.6.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.4}道案内を行うオブジェクトの描画}{18}{subsection.6.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第7章}実験}{19}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}実験準備}{19}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}全方位カメラパラメータ推定結果}{19}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}簡易モデル生成結果}{19}{section.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.4}特徴点マッチング手法の比較評価}{19}{section.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.5}特徴点マッチングに基づく自己位置推定結果の評価}{19}{section.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.6}屋内ナビゲーションにおける自己位置推定結果の比較}{20}{section.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第8章}まとめ}{21}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}本研究の成果}{21}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}今後の展望}{21}{section.8.2}\protected@file@percent }
\bibcite{IDC_DT_Survey2024}{1}
\bibcite{GlobalGrowthInsights_DT}{2}
\bibcite{ORB_SLAM}{3}
\bibcite{ORB_SLAM2}{4}
\bibcite{CNN_SLAM}{5}
\bibcite{Cadena2016}{6}
\bibcite{ImageLocalizationSfM}{7}
\bibcite{ImageRetrievalLocalization}{8}
\bibcite{IndoorSurvey}{9}
\bibcite{IndoorLiDARNav}{10}
\bibcite{2DMapLocalization}{11}
\bibcite{SimplifiedModelLocalization}{12}
\bibcite{Schindler2007}{13}
\bibcite{Sattler2011}{14}
\bibcite{Shewchuk1996Triangle}{15}
\bibcite{Sugaya2024}{16}
\bibcite{Lowe2004}{17}
\bibcite{Alcantarilla2013}{18}
\bibcite{DeTone2018SuperPoint}{19}
\bibcite{Sarlin2020SuperGlue}{20}
\gdef \@abspage@last{25}
