\contentsline {chapter}{\numberline {第1章}はじめに}{2}{chapter.1}%
\contentsline {section}{\numberline {1.1}研究背景}{2}{section.1.1}%
\contentsline {section}{\numberline {1.2}研究目的}{2}{section.1.2}%
\contentsline {section}{\numberline {1.3}関連研究}{3}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Visual SLAM による自己位置推定}{3}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}画像ベースの自己位置推定手法}{4}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}簡易3次元モデルを用いた位置推定}{4}{subsection.1.3.3}%
\contentsline {section}{\numberline {1.4}本論文の構成}{5}{section.1.4}%
\contentsline {chapter}{\numberline {第2章}簡易3次元モデルの生成}{6}{chapter.2}%
\contentsline {section}{\numberline {2.1}簡易3次元モデル生成の方針}{6}{section.2.1}%
\contentsline {section}{\numberline {2.2}座標系の定義}{6}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}カメラ座標系}{6}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}画像座標系}{7}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}カメラ内部パラメータの設定}{7}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}ワイヤーフレーム生成の方針}{8}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}ワイヤーフレーム生成の前提条件}{8}{subsection.2.3.1}%
\contentsline {section}{\numberline {2.4}2次元マップと3次元空間の対応付け}{9}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}アフィン変換による写像}{9}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}非線形な歪みへの対応}{9}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}頂点列の回転方向の判定と統一}{9}{subsection.2.4.3}%
\contentsline {section}{\numberline {2.5}カメラ位置に基づく床境界点の最適化}{10}{section.2.5}%
\contentsline {section}{\numberline {2.6}床面および壁面の幾何構造}{11}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}床面のメッシュ化}{11}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}壁面のメッシュ化}{12}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}UV座標の定義}{12}{subsection.2.6.3}%
\contentsline {section}{\numberline {2.7}全方位画像を用いたテクスチャ取得の方針}{13}{section.2.7}%
\contentsline {section}{\numberline {2.8}透視投影画像変換}{13}{section.2.8}%
\contentsline {section}{\numberline {2.9}透視投影画像を用いた全方位カメラの位置姿勢推定}{14}{section.2.9}%
\contentsline {section}{\numberline {2.10}メッシュの座標系変換と投影}{15}{section.2.10}%
\contentsline {subsection}{\numberline {2.10.1}テクスチャ候補の評価}{16}{subsection.2.10.1}%
\contentsline {subsection}{\numberline {2.10.2}カメラとメッシュの相対位置関係の導出}{16}{subsection.2.10.2}%
\contentsline {section}{\numberline {2.11}テクスチャ画像の形状変換}{17}{section.2.11}%
\contentsline {section}{\numberline {2.12}テクスチャの視覚的品質の改善}{18}{section.2.12}%
\contentsline {chapter}{\numberline {第3章}特徴点マッチングに基づく自己位置推定}{19}{chapter.3}%
\contentsline {section}{\numberline {3.1}特徴点検出およびマッチングの概要}{19}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}共通の前処理}{19}{subsection.3.1.1}%
\contentsline {section}{\numberline {3.2}従来手法による特徴点マッチング}{19}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}特徴点検出}{19}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}特徴点マッチング}{20}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}マッチングの精度向上}{20}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}学習ベース手法による特徴点マッチング}{20}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}特徴点検出}{20}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}特徴点マッチング}{21}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}マッチングの精度向上}{21}{subsection.3.3.3}%
\contentsline {section}{\numberline {3.4}テクスチャ画像座標から世界座標への変換}{22}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}2次元座標から3次元座標への変換}{22}{subsection.3.4.1}%
\contentsline {section}{\numberline {3.5}自己位置推定}{23}{section.3.5}%
\contentsline {chapter}{\numberline {第4章}自己位置推定結果を用いた屋内ナビゲーション}{25}{chapter.4}%
\contentsline {section}{\numberline {4.1}屋内ナビゲーションの方針}{25}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}簡易モデルによる自己位置推定の課題}{25}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}提案手法に基づく屋内ナビゲーションの基本方針}{25}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}Visual-Inertial Odometry (VIO) による自己位置推定}{25}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4}ARKitの座標系の定義}{26}{subsection.4.1.4}%
\contentsline {section}{\numberline {4.2}自己位置推定手法の比較検討方針}{27}{section.4.2}%
\contentsline {section}{\numberline {4.3}屋内ナビゲーションシステムの構成}{28}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}目的地設定}{28}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}カメラ画像取得および端末とPC間の通信}{29}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}自己位置推定結果の受信および座標系の更新}{29}{subsection.4.3.3}%
\contentsline {subsection}{\numberline {4.3.4}世界座標系とAR座標系の相互変換}{29}{subsection.4.3.4}%
\contentsline {subsection}{\numberline {4.3.5}目的地および進行方向オブジェクトの描画}{30}{subsection.4.3.5}%
\contentsline {chapter}{\numberline {第5章}実験}{32}{chapter.5}%
\contentsline {section}{\numberline {5.1}実験準備}{32}{section.5.1}%
\contentsline {section}{\numberline {5.2}簡易モデル生成}{33}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}データセットおよびパラメータ設定}{33}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}ワイヤーフレーム生成結果}{34}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}テクスチャ割り当て結果}{35}{subsection.5.2.3}%
\contentsline {section}{\numberline {5.3}特徴点マッチング手法の比較実験}{35}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}実験条件}{35}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}実験結果}{37}{subsection.5.3.2}%
\contentsline {section}{\numberline {5.4}特徴点マッチングに基づく自己位置推定結果の評価}{39}{section.5.4}%
\contentsline {section}{\numberline {5.5}屋内ナビゲーションにおける自己位置推定結果の比較}{40}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}実験条件}{40}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}実験結果}{40}{subsection.5.5.2}%
\contentsline {chapter}{\numberline {第6章}まとめ}{42}{chapter.6}%
\contentsline {section}{\numberline {6.1}本研究の成果}{42}{section.6.1}%
\contentsline {section}{\numberline {6.2}今後の展望}{42}{section.6.2}%
