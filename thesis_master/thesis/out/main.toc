\contentsline {chapter}{\numberline {第1章}はじめに}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}研究背景}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}研究目的}{1}{section.1.2}%
\contentsline {section}{\numberline {1.3}関連研究}{2}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Visual SLAM による自己位置推定}{2}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}画像ベースの自己位置推定手法}{2}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}簡易3次元モデルを用いた位置推定}{3}{subsection.1.3.3}%
\contentsline {section}{\numberline {1.4}本論文の構成}{3}{section.1.4}%
\contentsline {chapter}{\numberline {第2章}簡易3次元モデルの生成}{4}{chapter.2}%
\contentsline {section}{\numberline {2.1}簡易3次元モデル生成の方針}{4}{section.2.1}%
\contentsline {section}{\numberline {2.2}座標系の定義}{4}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}カメラ座標系}{4}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}画像座標系}{5}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}カメラ内部パラメータの設定}{5}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}ワイヤーフレーム生成の方針}{6}{section.2.3}%
\contentsline {section}{\numberline {2.4}2次元マップと3次元空間の対応付け}{6}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}アフィン変換による写像}{7}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}非線形な歪みへの対応}{7}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}頂点列の回転方向の判定と統一}{7}{subsection.2.4.3}%
\contentsline {section}{\numberline {2.5}カメラ位置に基づく床境界点の最適化}{8}{section.2.5}%
\contentsline {paragraph}{射影点の間隔が大きい場合}{9}{section*.8}%
\contentsline {paragraph}{射影点の間隔が小さい場合}{9}{section*.9}%
\contentsline {section}{\numberline {2.6}床面および壁面の幾何構造}{9}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}床面のメッシュ化}{10}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}壁面のメッシュ化}{10}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}UV座標の定義}{10}{subsection.2.6.3}%
\contentsline {section}{\numberline {2.7}全方位画像を用いたテクスチャ取得の方針}{11}{section.2.7}%
\contentsline {section}{\numberline {2.8}透視投影画像変換}{11}{section.2.8}%
\contentsline {section}{\numberline {2.9}透視投影画像を用いた全方位カメラの位置姿勢推定}{12}{section.2.9}%
\contentsline {section}{\numberline {2.10}メッシュの座標系変換と投影}{13}{section.2.10}%
\contentsline {section}{\numberline {2.11}テクスチャ画像の形状変換}{15}{section.2.11}%
\contentsline {section}{\numberline {2.12}テクスチャの視覚的品質の改善}{15}{section.2.12}%
\contentsline {subsection}{\numberline {2.12.1}カメラとメッシュの相対位置関係の導出}{16}{subsection.2.12.1}%
\contentsline {subsection}{\numberline {2.12.2}テクスチャのブレンド処理}{16}{subsection.2.12.2}%
\contentsline {chapter}{\numberline {第3章}特徴点マッチングに基づく自己位置推定}{18}{chapter.3}%
\contentsline {section}{\numberline {3.1}特徴点検出およびマッチングの概要}{18}{section.3.1}%
\contentsline {section}{\numberline {3.2}従来手法による特徴点マッチング}{18}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}特徴点検出}{18}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}特徴点マッチング}{19}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}マッチングの精度向上}{19}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}学習ベース手法による特徴点マッチング}{19}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}特徴点検出}{19}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}特徴点マッチング}{20}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}マッチングの精度向上}{20}{subsection.3.3.3}%
\contentsline {section}{\numberline {3.4}テクスチャ画像座標から世界座標への変換}{20}{section.3.4}%
\contentsline {section}{\numberline {3.5}自己位置推定}{21}{section.3.5}%
\contentsline {chapter}{\numberline {第4章}自己位置推定結果を用いた屋内ナビゲーション}{23}{chapter.4}%
\contentsline {section}{\numberline {4.1}屋内ナビゲーションの方針}{23}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}簡易モデルによる自己位置推定の課題}{23}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}提案手法に基づく屋内ナビゲーションの基本方針}{23}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}Visual-Inertial Odometry (VIO) による自己位置推定}{23}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4}ARKitの座標系の定義}{24}{subsection.4.1.4}%
\contentsline {section}{\numberline {4.2}自己位置推定手法の比較検討方針}{24}{section.4.2}%
\contentsline {section}{\numberline {4.3}屋内ナビゲーションシステムの構成}{25}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}目的地設定}{26}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}カメラ画像取得および端末とPC間の通信}{26}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}自己位置推定結果の受信および座標系の更新}{27}{subsection.4.3.3}%
\contentsline {subsection}{\numberline {4.3.4}世界座標系とAR座標系の相互変換}{27}{subsection.4.3.4}%
\contentsline {subsection}{\numberline {4.3.5}目的地および進行方向オブジェクトの描画}{28}{subsection.4.3.5}%
\contentsline {chapter}{\numberline {第5章}実験}{29}{chapter.5}%
\contentsline {section}{\numberline {5.1}実験準備}{29}{section.5.1}%
\contentsline {section}{\numberline {5.2}簡易モデル生成}{30}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}データセットおよびパラメータ設定}{30}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}ワイヤーフレーム生成結果}{31}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}テクスチャ割り当て結果}{32}{subsection.5.2.3}%
\contentsline {section}{\numberline {5.3}特徴点マッチング手法の比較実験}{32}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}実験条件}{32}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}実験結果}{34}{subsection.5.3.2}%
\contentsline {section}{\numberline {5.4}特徴点マッチングに基づく自己位置推定結果の評価}{36}{section.5.4}%
\contentsline {section}{\numberline {5.5}屋内ナビゲーションにおける自己位置推定結果の比較}{37}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}実験条件}{37}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}実験結果}{38}{subsection.5.5.2}%
\contentsline {subsection}{\numberline {5.5.3}アプリケーションの実行の様子}{39}{subsection.5.5.3}%
\contentsline {chapter}{\numberline {第6章}まとめ}{41}{chapter.6}%
\contentsline {section}{\numberline {6.1}本研究の成果}{41}{section.6.1}%
\contentsline {section}{\numberline {6.2}今後の展望}{41}{section.6.2}%
