\contentsline {chapter}{\numberline {第1章}はじめに}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}研究背景}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}研究目的}{1}{section.1.2}%
\contentsline {section}{\numberline {1.3}関連研究}{2}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Visual SLAM による自己位置推定と三次元マッピング}{2}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}画像ベースの自己位置推定手法}{3}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}簡易3次元モデルを用いた位置推定}{3}{subsection.1.3.3}%
\contentsline {section}{\numberline {1.4}本論文の構成}{4}{section.1.4}%
\contentsline {chapter}{\numberline {第2章}簡易モデルを構成するワイヤーフレームの生成}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}ワイヤーフレーム生成の方針}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}入力情報と前提条件}{5}{subsection.2.1.1}%
\contentsline {section}{\numberline {2.2}2次元マップと3次元空間の対応付け}{6}{section.2.2}%
\contentsline {section}{\numberline {2.3}床境界におけるカメラ位置に基づくサンプリング}{6}{section.2.3}%
\contentsline {section}{\numberline {2.4}床面および壁面の幾何構造}{8}{section.2.4}%
\contentsline {chapter}{\numberline {第3章}簡易モデルへのテクスチャ割り当て}{9}{chapter.3}%
\contentsline {section}{\numberline {3.1}全方位画像から透視投影画像生成}{9}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}全方位画像を用いたテクスチャ取得の方針}{9}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}透視投影画像変換}{9}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}座標系の定義}{10}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}カメラ座標系}{10}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}画像座標系}{10}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}カメラ内部パラメータの設定}{11}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}複数の透視投影カメラによる全方位カメラ位置姿勢推定}{11}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}座標系変換と投影}{12}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}テクスチャ候補の評価}{12}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}テクスチャの射影変換}{13}{subsection.3.3.3}%
\contentsline {section}{\numberline {3.4}テクスチャの視覚的品質の改善}{13}{section.3.4}%
\contentsline {chapter}{\numberline {第4章}入力画像とテクスチャの特徴点マッチング}{14}{chapter.4}%
\contentsline {section}{\numberline {4.1}特徴点検出およびマッチングの概要}{14}{section.4.1}%
\contentsline {section}{\numberline {4.2}従来手法による特徴点マッチング}{14}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}特徴点検出}{14}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}特徴点マッチング}{14}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}マッチングの精度向上}{15}{subsection.4.2.3}%
\contentsline {section}{\numberline {4.3}学習ベース手法による特徴点マッチング}{15}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}特徴点検出}{15}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}特徴点マッチング}{16}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}マッチングの精度向上}{16}{subsection.4.3.3}%
\contentsline {chapter}{\numberline {第5章}特徴点マッチングに基づく自己位置推定}{17}{chapter.5}%
\contentsline {section}{\numberline {5.1}テクスチャ画像座標から世界座標への変換}{17}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}2次元座標から3次元座標への変換}{17}{subsection.5.1.1}%
\contentsline {section}{\numberline {5.2}自己位置推定}{17}{section.5.2}%
\contentsline {chapter}{\numberline {第6章}自己位置推定結果を用いた屋内ナビゲーション}{19}{chapter.6}%
\contentsline {section}{\numberline {6.1}屋内ナビゲーションの方針}{19}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}簡易モデルによる自己位置推定の課題}{19}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}提案手法に基づく屋内ナビゲーションの基本方針}{19}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}(Visual-Inertial Odometory)による自己位置推定}{19}{subsection.6.1.3}%
\contentsline {section}{\numberline {6.2}自己位置推定手法の使い分けと比較方針}{21}{section.6.2}%
\contentsline {section}{\numberline {6.3}屋内ナビゲーションシステムの構成}{21}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}目的地設定}{22}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}カメラ画像取得および端末とPC間の通信}{22}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}自己位置推定結果の受信および座標系の更新}{22}{subsection.6.3.3}%
\contentsline {subsection}{\numberline {6.3.4}変換行列の計算}{22}{subsection.6.3.4}%
\contentsline {subsection}{\numberline {6.3.5}目的地および進行方向オブジェクトの描画}{23}{subsection.6.3.5}%
\contentsline {chapter}{\numberline {第7章}実験}{25}{chapter.7}%
\contentsline {section}{\numberline {7.1}実験準備}{25}{section.7.1}%
\contentsline {section}{\numberline {7.2}簡易モデル生成}{26}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}データセットおよびパラメータ設定}{26}{subsection.7.2.1}%
\contentsline {subsection}{\numberline {7.2.2}ワイヤーフレーム生成結果}{27}{subsection.7.2.2}%
\contentsline {subsection}{\numberline {7.2.3}テクスチャ割り当て結果}{28}{subsection.7.2.3}%
\contentsline {section}{\numberline {7.3}特徴点マッチング手法の比較実験}{28}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}実験条件}{28}{subsection.7.3.1}%
\contentsline {subsection}{\numberline {7.3.2}実験結果}{30}{subsection.7.3.2}%
\contentsline {section}{\numberline {7.4}特徴点マッチングに基づく自己位置推定結果の評価}{32}{section.7.4}%
\contentsline {section}{\numberline {7.5}屋内ナビゲーションにおける自己位置推定結果の比較}{33}{section.7.5}%
\contentsline {subsection}{\numberline {7.5.1}実験条件}{33}{subsection.7.5.1}%
\contentsline {subsection}{\numberline {7.5.2}実験結果}{33}{subsection.7.5.2}%
\contentsline {chapter}{\numberline {第8章}まとめ}{35}{chapter.8}%
\contentsline {section}{\numberline {8.1}本研究の成果}{35}{section.8.1}%
\contentsline {section}{\numberline {8.2}今後の展望}{35}{section.8.2}%
