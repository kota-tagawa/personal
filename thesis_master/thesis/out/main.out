\BOOKMARK [0][-]{chapter.1}{第1章 はじめに}{}% 1
\BOOKMARK [1][-]{section.1.1}{1.1 研究背景}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{1.2 研究目的}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.3}{1.3 関連研究}{chapter.1}% 4
\BOOKMARK [2][-]{subsection.1.3.1}{1.3.1 Visual SLAM による自己位置推定と三次元マッピング}{section.1.3}% 5
\BOOKMARK [2][-]{subsection.1.3.2}{1.3.2 画像ベースの自己位置推定手法}{section.1.3}% 6
\BOOKMARK [2][-]{subsection.1.3.3}{1.3.3 簡易3次元モデルを用いた位置推定}{section.1.3}% 7
\BOOKMARK [1][-]{section.1.4}{1.4 本論文の構成}{chapter.1}% 8
\BOOKMARK [0][-]{chapter.2}{第2章 簡易モデルを構成するワイヤーフレームの生成}{}% 9
\BOOKMARK [1][-]{section.2.1}{2.1 ワイヤーフレーム生成の方針}{chapter.2}% 10
\BOOKMARK [2][-]{subsection.2.1.1}{2.1.1 入力情報と前提条件}{section.2.1}% 11
\BOOKMARK [1][-]{section.2.2}{2.2 2次元マップと3次元空間の対応付け}{chapter.2}% 12
\BOOKMARK [1][-]{section.2.3}{2.3 床境界における観測点に基づくサンプリング}{chapter.2}% 13
\BOOKMARK [1][-]{section.2.4}{2.4 床面および壁面の幾何構造}{chapter.2}% 14
\BOOKMARK [0][-]{chapter.3}{第3章 簡易モデルへのテクスチャ割り当て}{}% 15
\BOOKMARK [1][-]{section.3.1}{3.1 全方位画像から透視投影画像生成}{chapter.3}% 16
\BOOKMARK [2][-]{subsection.3.1.1}{3.1.1 全方位画像を用いたテクスチャ取得の方針}{section.3.1}% 17
\BOOKMARK [2][-]{subsection.3.1.2}{3.1.2 透視投影画像変換}{section.3.1}% 18
\BOOKMARK [1][-]{section.3.2}{3.2 座標系の定義}{chapter.3}% 19
\BOOKMARK [2][-]{subsection.3.2.1}{3.2.1 カメラ座標系}{section.3.2}% 20
\BOOKMARK [2][-]{subsection.3.2.2}{3.2.2 画像座標系}{section.3.2}% 21
\BOOKMARK [2][-]{subsection.3.2.3}{3.2.3 カメラ内部パラメータの設定}{section.3.2}% 22
\BOOKMARK [1][-]{section.3.3}{3.3 複数の透視投影カメラによる全方位カメラ位置姿勢推定}{chapter.3}% 23
\BOOKMARK [2][-]{subsection.3.3.1}{3.3.1 座標系変換と投影}{section.3.3}% 24
\BOOKMARK [2][-]{subsection.3.3.2}{3.3.2 テクスチャ候補の評価}{section.3.3}% 25
\BOOKMARK [1][-]{section.3.4}{3.4 テクスチャの射影変換}{chapter.3}% 26
\BOOKMARK [1][-]{section.3.5}{3.5 テクスチャの視覚的品質の改善}{chapter.3}% 27
\BOOKMARK [0][-]{chapter.4}{第4章 入力画像とテクスチャの特徴点マッチング}{}% 28
\BOOKMARK [1][-]{section.4.1}{4.1 特徴点検出およびマッチングの概要}{chapter.4}% 29
\BOOKMARK [1][-]{section.4.2}{4.2 従来手法による特徴点マッチング}{chapter.4}% 30
\BOOKMARK [2][-]{subsection.4.2.1}{4.2.1 特徴点検出}{section.4.2}% 31
\BOOKMARK [2][-]{subsection.4.2.2}{4.2.2 特徴点マッチング}{section.4.2}% 32
\BOOKMARK [2][-]{subsection.4.2.3}{4.2.3 マッチングの精度向上}{section.4.2}% 33
\BOOKMARK [1][-]{section.4.3}{4.3 学習ベース手法による特徴点マッチング}{chapter.4}% 34
\BOOKMARK [2][-]{subsection.4.3.1}{4.3.1 特徴点検出}{section.4.3}% 35
\BOOKMARK [2][-]{subsection.4.3.2}{4.3.2 特徴点マッチング}{section.4.3}% 36
\BOOKMARK [2][-]{subsection.4.3.3}{4.3.3 マッチングの精度向上}{section.4.3}% 37
\BOOKMARK [0][-]{chapter.5}{第5章 特徴点マッチングに基づく自己位置推定}{}% 38
\BOOKMARK [1][-]{section.5.1}{5.1 テクスチャ画像座標から世界座標への変換}{chapter.5}% 39
\BOOKMARK [2][-]{subsection.5.1.1}{5.1.1 2次元座標から3次元座標への変換}{section.5.1}% 40
\BOOKMARK [1][-]{section.5.2}{5.2 自己位置推定}{chapter.5}% 41
\BOOKMARK [0][-]{chapter.6}{第6章 自己位置推定結果を用いた屋内ナビゲーション}{}% 42
\BOOKMARK [1][-]{section.6.1}{6.1 屋内ナビゲーションの方針}{chapter.6}% 43
\BOOKMARK [2][-]{subsection.6.1.1}{6.1.1 簡易モデルによる自己位置推定の課題}{section.6.1}% 44
\BOOKMARK [2][-]{subsection.6.1.2}{6.1.2 提案手法に基づく屋内ナビゲーションの基本方針}{section.6.1}% 45
\BOOKMARK [2][-]{subsection.6.1.3}{6.1.3 ARKitによる自己位置推定}{section.6.1}% 46
\BOOKMARK [1][-]{section.6.2}{6.2 自己位置推定手法の使い分けと比較方針}{chapter.6}% 47
\BOOKMARK [1][-]{section.6.3}{6.3 屋内ナビゲーションシステムの構成}{chapter.6}% 48
\BOOKMARK [2][-]{subsection.6.3.1}{6.3.1 目的地設定}{section.6.3}% 49
\BOOKMARK [2][-]{subsection.6.3.2}{6.3.2 カメラ画像取得および端末とPC間の通信}{section.6.3}% 50
\BOOKMARK [2][-]{subsection.6.3.3}{6.3.3 自己位置推定結果の受信および座標系の更新}{section.6.3}% 51
\BOOKMARK [2][-]{subsection.6.3.4}{6.3.4 変換行列の計算}{section.6.3}% 52
\BOOKMARK [2][-]{subsection.6.3.5}{6.3.5 目的地および進行方向オブジェクトの描画}{section.6.3}% 53
\BOOKMARK [0][-]{chapter.7}{第7章 実験}{}% 54
\BOOKMARK [1][-]{section.7.1}{7.1 実験準備}{chapter.7}% 55
\BOOKMARK [1][-]{section.7.2}{7.2 全方位カメラパラメータ推定結果}{chapter.7}% 56
\BOOKMARK [1][-]{section.7.3}{7.3 簡易モデル生成結果}{chapter.7}% 57
\BOOKMARK [1][-]{section.7.4}{7.4 特徴点マッチング手法の比較評価}{chapter.7}% 58
\BOOKMARK [1][-]{section.7.5}{7.5 特徴点マッチングに基づく自己位置推定結果の評価}{chapter.7}% 59
\BOOKMARK [1][-]{section.7.6}{7.6 屋内ナビゲーションにおける自己位置推定結果の比較}{chapter.7}% 60
\BOOKMARK [0][-]{chapter.8}{第8章 まとめ}{}% 61
\BOOKMARK [1][-]{section.8.1}{8.1 本研究の成果}{chapter.8}% 62
\BOOKMARK [1][-]{section.8.2}{8.2 今後の展望}{chapter.8}% 63
