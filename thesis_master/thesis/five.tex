\chapter{実験}

\section{実験準備}
表\ref{five:one}に実験で使用した機材および実行環境を示す。
\begin{table}[H]
  \centering
  \caption{実験で使用した機材および実行環境}
  \label{five:one}
  \begin{tabular}{l|l}
    \hline
    項目 & 内容 \\
    \hline \hline
    全方位カメラ & RECOH THETA 360 \\
    全方位カメラ解像度 & 11K $(11008 \times 5504)$ \\
    全方位カメラ焦点距離 & 約1752 \\
    \hline
    OS & Windows 11 \\
    CPU & Intel Core i7-14700 \\
    GPU & NVIDIA GeForce RTX 4060 Ti \\
    メモリ & 32 GB \\
    使用言語 & Python 3.9.13 \\
    主な使用ライブラリ & PyTorch 2.5.1+cu121 ,OpenCV 4.10 \\
    \hline
    屋内ナビゲーション端末 & iPad Pro 12.9インチ (第5世代) \\
    OS (iOS) & 17.5 \\
    端末カメラ解像度 & ($1920 \times 1440$) \\
    端末カメラ焦点距離 & 約1595 \\
    \hline
    屋内ナビゲーション実装環境 & MacBook Air 13インチ \\
    使用言語 & swift 5.10 \\
    主な使用ライブラリ & ARKit, SceanKit \\
    \hline
  \end{tabular}
\end{table}

簡易モデルの作成および屋内ナビゲーションに関する実験は、所属する大学のC棟5階において実施した。
当該フロアは廊下および複数の部屋から構成されており、単色壁面が連続するテクスチャの少ない領域が存在する。
C棟5階のフロアマップおよび、全方位画像の撮影位置を図\ref{five:two}に示す。
全方位画像は、一部の例外を除き、およそ 4\,m 間隔で合計 $N$ 箇所において撮影した。
撮影時のカメラ高さは床面から 1.4\,m である。

ただし、当該環境には類似した外観を有する領域が多く、特徴点マッチングに必要な情報が十分に得られない箇所が存在する。
そこで本研究では、過度に環境のテクスチャ量を増加させることなく、最低限の特徴情報を得ることを目的として、
壁面の一部に A2 サイズのポスターを掲示した。
ポスターの掲示間隔はおよそ 4\,m に1枚程度とし、環境全体が高テクスチャ化することを避けるよう配慮した。

\begin{figure}[H]
  \centering
  \begin{tabular}{c}
      \includegraphics[width=0.4\textwidth]{figures/5/camera.png}
  \end{tabular}
  \caption{世界座標系とカメラ座標系、画像座標系の関係}
  \label{five:two}
\end{figure}

各全方位カメラについては、2方向以上の透視投影画像を画角$90 \times 90$で生成し、
図\ref{five:three}に示すように透視投影画像上の2次元座標と世界座標の3次元座標を対応付けることで、全方位カメラの位置と姿勢を推定した。
すべての全方位カメラにおいて、推定位置と実測位置のずれが$10cm$未満であることを確認している。

\begin{figure}[H]
  \centering
  \begin{tabular}{ccc}
    \includegraphics[width=0.4\textwidth]{figures/5/omni.png} &
    \includegraphics[width=0.3\textwidth]{figures/5/pers1.png} &
    \includegraphics[width=0.3\textwidth]{figures/5/pers2.png}
  \end{tabular}
  \caption{全方位画像(10番)と前後の透視投影画像}
  \label{five:three}
\end{figure}

\section{簡易モデル生成}
\subsection{データセットおよびパラメータ設定}
図\ref{five:four}に、ワイヤーフレーム生成の入力として用いた、
簡易モデルの床面の境界点を示す。
これらの点は、2次元マップ上で手動により入力されたものである。

\begin{figure}[H]
  \centering
  \begin{tabular}{c}
      \includegraphics[width=0.4\textwidth]{figures/5/corners.png}
  \end{tabular}
  \caption{ワイヤーフレームの床面の境界点}
  \label{five:four}
\end{figure}

床面は三角形メッシュとして分割し、各三角形の最大面積を 2.0\,m$^2$ に制限した。
側面は四角形メッシュとして分割し、天井高は 2.3\,m とした。
サンプリング間隔については、間隔の違いがテクスチャ割り当て後の外観および自己位置推定結果に与える影響を確認するため、2\,m、3\,m、4\,m の3種類を設定した。

\subsection{ワイヤーフレーム生成結果}
図\ref{five:five}に、これらのコーナー点を結ぶ辺に沿って所定のサンプリング間隔で補間点を生成することで構築した
ワイヤーフレームモデルを示す。サンプリング間隔は左から 2\,m、3\,m、4\,m である。
床面の三角形メッシュは、コーナー点および補間点に基づいて自動的に三角形分割されていることが確認できる。
一方、壁面の四角形メッシュについては、サンプリング間隔の変化に伴い生成されるメッシュ形状が変化していることが観察される。

\begin{figure}[H]
  \centering
  \begin{tabular}{ccc}
    \includegraphics[width=0.33\textwidth]{figures/5/wire1.png} &
    \includegraphics[width=0.33\textwidth]{figures/5/wire2.png} &
    \includegraphics[width=0.33\textwidth]{figures/5/wire3.png}
  \end{tabular}
  \caption{ワイヤーフレームの床面の境界点（サンプリング間隔：左から 4\,m, 3\,m, 2\,m）}
  \label{five:five}
\end{figure}

\subsection{テクスチャ割り当て結果}
図\ref{five:six}に、前節で生成したワイヤーフレームモデルに対して、全方位画像からテクスチャを割り当てた結果を示す。
なお、壁面ではなく奥行きを有する面については、誤った特徴点座標が自己位置推定に用いられることを防ぐため、あらかじめテクスチャ割り当ての対象から除外している。

\begin{figure}[H]
  \centering
  \begin{tabular}{c}
    \includegraphics[width=0.8\textwidth]{figures/5/3dmodel.png}
  \end{tabular}
  \caption{簡易モデルの全体図}
  \label{five:six}
\end{figure}

図\ref{five:seven}に、サンプリング間隔の異なるワイヤーフレームごとに、拡大表示した簡易モデルを示す。
いずれのサンプリング間隔においても、テクスチャは大きな位置ずれを生じることなく、
各面に対して適切に割り当てられていることが確認できる。
また、ブレンド処理を行った場合には、隣接するテクスチャ間の接続が滑らかになり、
視覚的品質の向上に寄与していることがわかる。

サンプリング間隔の違いによる全体的な再現度の差は大きくないものの、
サンプリング間隔が 4\,m の場合には、テクスチャを大きく拡大して生成する必要があるため、
引き延ばしによる劣化が確認される。
一方で、3\,m の場合には、面ごとに割り当てられるテクスチャの大きさにばらつきが生じる点が確認された。
これらの点から、視覚的品質の観点では、2\,m のサンプリング間隔が最も適していると考えられる。

\begin{figure}[H]
  \centering
  \begin{tabular}{ccc}
    \includegraphics[width=0.33\textwidth]{figures/5/4m.png}
    \includegraphics[width=0.33\textwidth]{figures/5/3m.png}
    \includegraphics[width=0.33\textwidth]{figures/5/2m.png}
  \end{tabular}
  \caption{簡易モデルの拡大図（サンプリング間隔：左から 4\,m, 3\,m, 2\,m）}
  \label{five:seven}
\end{figure}

\section{特徴点マッチング手法の比較実験}

\subsection{実験条件}
前節で生成した簡易モデルのテクスチャと、実環境で撮影された入力画像との間で特徴点マッチングを行い、その精度を評価した。
入力データには、大学構内C棟5階の廊下環境において、屋内ナビゲーション端末を保持して歩行撮影した動画を用いた。
歩行経路と、入力動画を一部切り抜いたものを表\ref{five:input}に示す。
動画の解像度は$1920 \times 1080$ピクセルであり、これを1fps(frame per second)の間隔で静止画として切り出し、評価用画像セットとした。

\begin{figure}[H]
    \centering
    \begin{minipage}[c]{0.35\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/5/directions.png}
    \end{minipage}
    \hspace{1cm}
    \begin{minipage}[c]{0.35\textwidth}
        \centering
        \begin{subfigure}{\linewidth}
            \centering
            \includegraphics[width=\linewidth]{figures/5/input1.jpg}
        \end{subfigure}
        \vspace{2em}
        \begin{subfigure}{\linewidth}
            \centering
            \includegraphics[width=\linewidth]{figures/5/input2.jpg}
        \end{subfigure}
    \end{minipage}
    \caption{歩行経路と入力画像}
    \label{five:input}
\end{figure}

屋内ナビゲーションを目的とした走行環境においては、カメラが壁面や掲示物に対して正対する状況は限定的であり、
進行方向に対して壁面を斜め方向から観測する頻度が高いと考えられる。
したがって本実験では、視点変化や変形に対する頑健性を確保することを最優先としつつ、
ナビゲーション用途としてのリアルタイム性も考慮してパラメータ調整を行った。
表\ref{five:eight}にSIFTおよびAKAZE検出器の主なパラメータを示す。

\begin{table}[H]
  \centering
  \caption{従来手法（SIFT, AKAZE）のパラメータ設定}
  \label{five:eight}
  \begin{tabular}{l|l|c|c}
    \hline
    手法 & パラメータ項目 & 標準値 & \textbf{本実験設定値} \\
    \hline \hline
    SIFT & \texttt{nOctaveLayers} & 3 & \textbf{5} \\
    & \texttt{contrastThreshold} & 0.04 & \textbf{0.03} \\
    & \texttt{edgeThreshold} & 10 & \textbf{20} \\
    \hline
    AKAZE & \texttt{threshold} & 0.001 & \textbf{0.0005} \\
    & \texttt{nOctaveLayers} & 4 & \textbf{6} \\
    \hline
  \end{tabular}
\end{table}

一方、深層学習ベースの手法であるSuperPointおよびSuperGlueについても、同様に計算効率と精度のトレードオフを考慮した設定を用いた。
表\ref{five:nine}にSuperPointおよびSuperGlueのパラメータを示す。

\begin{table}[H] 
  \centering 
  \caption{深層学習手法（SuperPoint, SuperGlue）のパラメータ設定} 
  \label{five:nine} 
  \begin{tabular}{l|l|c|l} 
    \hline 
    モデル & パラメータ項目 & 標準値 & \textbf{本実験設定値} \\ 
    \hline \hline 
    SuperPoint & \texttt{max\_keypoints} & \mbox{無制限} & \textbf{1024} \\
    & \texttt{keypoint\_threshold} & 0.005 & \textbf{0.001} \\ 
    \hline 
    SuperGlue & \texttt{weights} & --- & \textbf{outdoor} \\ 
    & \texttt{sinkhorn\_iterations} & 20 & \textbf{5} \\
    \hline 
  \end{tabular} 
\end{table}

SuperGlueの重みパラメータについては、屋内環境での実験であるものの、屋外データで学習された \texttt{outdoor} モデルを採用した。
一般に屋内では \texttt{indoor} モデルが推奨されるが、本研究の対象である「大学構内の廊下」においては、以下の3点の理由から屋外モデルの方が適していると判断した。

\begin{enumerate}
    \item \textbf{環境の構造的特徴:}
    一般的な屋内学習データは、狭い部屋に置かれた家具や雑貨などの豊富な模様を頼りに学習されている傾向がある。
    一方、本実験の環境である廊下は、模様が少なく、長い白壁や天井のラインといった直線的な構造が大部分を占めている。
    この特徴は、複雑な室内よりも、むしろビルの外観や道路といった屋外環境の構造に近い。

    \item \textbf{視点変化への強さ:}
    ナビゲーション中のカメラ映像は、壁に近づいたり、斜め方向から撮影したりと、見え方が大きく変化する。
    屋外モデルは、建物を様々な角度から撮影したデータで学習されているため、こうした大きな視点変化に対して頑健である。
    細かい模様に頼りがちな屋内モデルと比較して、廊下のような大まかな空間構造を捉える能力に長けていると考えられる。

    \item \textbf{予備実験による裏付け:}
    実際に本環境のデータを用いて比較実験を行ったところ、屋内モデルを使用した場合よりも、
    屋外モデルを使用した方が安定して多くのマッチング点が得られる傾向が確認された。
\end{enumerate}

マッチング後の誤対応除去については、各手法の純粋な性能を公平に比較するため、処理条件を統一した。 
ホモグラフィ行列の推定アルゴリズムには、従来のRANSACと比較してパラメータ依存性が低く、
ノイズに対してロバストな MAGSAC++ を採用した\cite{magsac}。 
再投影誤差の許容閾値は、入力が高解像度画像であることを考慮し 5.0 ピクセルに設定した。 
また、計算コストの増大を防ぎ推定精度を安定化させるため、検出された全マッチング点を用いるのではなく、
マッチングスコア上位の 100点 を選抜して幾何学的検証に入力する構成とした。

\subsection{実験結果}
図\ref{five:ten}に、従来手法（SIFT, AKAZE）および学習ベースの手法（SuperPoint+SuperGlue）を用いた
特徴点マッチングの定性的な評価結果の一部を示す。
図の左列に示すように、生成モデルのテクスチャと入力画像との間の視点差が小さいケースにおいては、
3手法ともに十分なインライア数を確保し、安定したマッチングに成功した。各手法ごとの詳細な傾向は以下の通りである。

\begin{itemize} 
  \item \textbf{SIFT:} 
  視点角度が類似している条件下であれば、撮影距離が離れている場合であってもマッチングが可能であった。
  しかし、壁面を斜めから見るなど視点変化が大きくなると、マッチングに失敗する事例が多発した。

  \item \textbf{AKAZE:} 
  SIFTと同様の傾向を示したが、SIFTと比較して視点変化に対する耐性がわずかに優れており、
  より広い角度範囲でマッチングを維持できる傾向が見られた。

  \item \textbf{SuperPoint+SuperGlue:} 
  従来手法と比較して、視点変化に対する頑健性が著しく向上した。
  極端にテクスチャが乏しい領域や、ドア等類似構造しか含まない領域といった高難度なケースを除き、
  ほぼ全てのフレームにおいてマッチングに成功した。
\end{itemize}

\begin{figure}[H]
  \centering
  \begin{tabular}{cc}
    \includegraphics[width=0.5\textwidth]{figures/5/sift1.jpg}
    \includegraphics[width=0.5\textwidth]{figures/5/sift2.jpg}\\
    \includegraphics[width=0.5\textwidth]{figures/5/akaze1.jpg}
    \includegraphics[width=0.5\textwidth]{figures/5/akaze2.jpg}\\
    \includegraphics[width=0.5\textwidth]{figures/5/deep1.jpg}
    \includegraphics[width=0.5\textwidth]{figures/5/deep2.jpg}\\
  \end{tabular}
  \caption{特徴点マッチング結果の比較\\上段から SIFT、AKAZE、SuperPoint+SuperGlue を示し、画像内左はテクスチャ画像，右は入力画像である。}
  \label{five:ten}
\end{figure}

表\ref{five:eleven}に、各手法におけるマッチング成功枚数および1フレームあたりの平均処理時間を示す。
マッチング成功数については、学習ベースの手法（SuperPoint+SuperGlue）が従来手法（SIFT, AKAZE）と比較して圧倒的に高い値を示した。
この主な要因は、学習ベース手法が持つ視点変化に対する高い頑健性にある。
テクスチャ情報が有効に撮像されているフレームにおいては、角度やスケールの変化に関わらず、
ほぼ全てのケースでマッチングに成功していることが確認された。

一方、平均処理時間に関しては、本実験の設定下ではAKAZEが最も高速な結果となった。
学習ベースの手法は推論処理を伴うため計算コストが高い傾向にある。
しかし、本実験では評価のために全フレームに対して探索を行っているが、実際のナビゲーション運用時においては、
一度自己位置が推定された後は近傍のテクスチャのみを探索対象とする処理を導入することで、計算時間は大幅に削減可能であると考えられる。
加えて、学習ベースの手法は低解像度画像に対しても高い特徴記述能力を維持する特性があるため、入力解像度をさらに低減させることによる高速化の余地も残されている。

以上の結果より、視点変化が大きく特徴点の抽出が困難な屋内ナビゲーション環境においては、
処理速度の課題を運用上の工夫で吸収可能であることを踏まえると、ロバスト性に優れる学習ベースの手法が最も適しているといえる。
したがって、以降の章では特徴点マッチングに学習ベースの手法を採用する。

\begin{table}[H]
  \centering
  \caption{各手法におけるマッチング成功枚数と平均処理時間}
  \label{five:eleven}
  \begin{tabular}{l|c|c}
    \hline
    手法 & マッチング成功枚数(全156枚中) & 平均処理時間[ms] \\
    \hline \hline
    SIFT & 12 & 4628 \\
    AKAZE & 20 & \textbf{147} \\
    SuperPoint+SuperGlue & \textbf{89} & 4112 \\
    \hline
  \end{tabular}
\end{table}

\section{特徴点マッチングに基づく自己位置推定結果の評価}\label{localization}
図\ref{five:twelve}に、前節で述べた学習ベースの手法による特徴点マッチングを用いた自己位置推定の結果を示す。
同図では、マッチングに成功したフレームについて、推定された自己位置および正規化された視線方向ベクトルをプロットしている。 
なお、実数解が得られなかった場合や、天地反転などの幾何学的に不整合な解しか得られなかった場合は、
有効な解が算出されなかったものとみなし、結果から除外している。
本実験では、図\ref{five:seven}に示したサンプリング間隔の異なる3種類の簡易モデルを用いて比較を行った。

\begin{figure}[H]
  \centering
  \begin{tabular}{ccc}
    \includegraphics[width=0.33\textwidth]{figures/5/deep4m.png}
    \includegraphics[width=0.33\textwidth]{figures/5/deep3m.png}
    \includegraphics[width=0.33\textwidth]{figures/5/deep2m.png}
  \end{tabular}
  \caption{自己位置推定結果（サンプリング間隔：左から 4\,m, 3\,m, 2\,m）}
  \label{five:twelve}
\end{figure}

実験の結果、学習ベース手法の場合いずれのサンプリング間隔においても、多くのフレームで自己位置推定が可能であることが確認された。 
しかし、サンプリング間隔4\,mの場合については、3\,mおよび2\,mの場合と比較して結果に顕著な差異が見られた。
具体的には、特徴点マッチングには成功しているものの、前後のフレーム間で姿勢が不連続に変化したり、
推定位置が経路から大きく逸脱したりする誤推定のフレームが多く確認された。
今回は、
特徴点マッチングに成功したフレームのうち、このような誤推定を除外した有効なフレーム数の割合は、
サンプリング間隔4\,mで90\%、3\,mで約96\%、2\,mで約95\%であった。 
3\,mと2\,mはいずれも高い推定成功率を示し、その差はわずかであった。 そのため、テクスチャの視覚的品質と自己位置推定の安定性を総合的に評価し、
本研究ではサンプリング間隔2\,mが最も適していると判断した。

\subsubsection*{自己位置推定に失敗したケース}
特徴点マッチングには成功しているものの、算出された自己位置や姿勢が真値と大きく乖離したケースを
図\ref{five:fourteen}に示す。なお、これらはすべてサンプリング間隔2\,mのデータベースを用いた際の結果である。

\begin{figure}[H]
  \centering
  \begin{tabular}{cc}
    \includegraphics[width=0.4\textwidth]{figures/5/fail1.jpg}&
    \includegraphics[width=0.4\textwidth]{figures/5/fail2.jpg}\\
    (a) 類似テクスチャへの誤マッチング & (b) 撮影角度による推定精度の低下
  \end{tabular}
  \caption{自己位置推定に失敗したケース}
  \label{five:fourteen}
\end{figure}

左図(a)は、環境内に類似したテクスチャや構造物が複数存在するケースである。
本来の場所とは異なる、似通った特徴を持つ別の地点に対して誤ってマッチングが成立してしまい、結果として全く異なる位置が推定されている。

右図(b)は、一見すると特徴点マッチングが正しく行われているように見えるが、正しい位置姿勢が得られなかったケースである。
本事例における最大の特徴は、壁面の法線に対してカメラの光軸方向がなす角度が大きく、対象を斜め方向から観測している点にある。
このような条件下では、透視投影による画像歪みが顕著となるため、
特徴点の検出や記述子のマッチングにおいて、画素座標を整数値に丸め込む際などに生じる量子化誤差の影響が大きくなる。
その結果、正面から観測する場合に比べて、対応付けで生じるズレが大きくなり、最終的な位置姿勢推定の結果が不安定になったと考えられる。
ただし、同様に角度がついている場合でも正しく推定できる事例も確認されており、
特徴点の配置パターンやノイズの具体的な組み合わせなど、推定失敗に至る決定的な条件の特定には至っていない。


\section{屋内ナビゲーションにおける自己位置推定結果の比較}

\subsection{実験条件}

本実験では、屋内ナビゲーションにおける自己位置推定手法の差異が、
最終的なナビゲーションの成否や精度に与える影響を検証するため、以下の3つの条件を設定し比較を行った。

\begin{enumerate}
    \item \textbf{画像マッチング単独:}
    本研究で提案した、簡易モデルを用いた特徴点マッチングによる自己位置推定の結果のみを用いる。
    \item \textbf{VIO単独:}
    モバイル端末に搭載されたVIO (Visual-Inertial Odometry) ベースの自己位置推定の結果のみを用いる。
    \item \textbf{併用手法:}
    両者を併用し、VIOによるトラッキングと画像マッチングによる補正を組み合わせる。
\end{enumerate}

歩行経路および経由地は、前節の図\ref{five:input}に示したものと同一である。
ただし、本実験では入力データとして録画済みの動画ではなく、リアルタイムに取得されるカメラ画像を用いた。
ナビゲーションの具体的な手順は以下の通りである。

\begin{enumerate}
    \item \textbf{開始処理:}
    開始地点にて静止し、初回の自己位置推定を行う。位置が特定され次第、第一の経由地へ向けて歩行を開始する。
    \item \textbf{経由地判定:}
    設定された経由地の半径2\,m以内に到達した時点で、システムは当該地点への到達と判定し、直ちに次の経由地へのナビゲーションに切り替える。
    \item \textbf{終了判定:}
    最終目的地の半径2\,m以内に到達した時点でナビゲーションを終了とする。
    \item \textbf{リカバリ処理:}
    PCサーバーによる位置推定が20秒間連続して成功しなかった場合、トラッキングが喪失したと判定し、再度初期位置推定処理を実行する。
\end{enumerate}

PCサーバー側で行う2回目以降の自己位置推定においては、計算効率と精度向上のため、
モバイル端末から得られる直前の推定位置および視線ベクトルを事前情報として利用する。
この際、誤マッチングによる外れ値を排除するため、許容誤差の閾値を位置については1\,m、姿勢については10$^{\circ}$と設定した。
また、計算コスト削減のため、特徴点マッチングを行う参照画像は、
現在の推定端末位置から半径5\,m以内に存在する画像のみを探索対象とした。

\subsection{実験結果}
図\ref{five:thirteen}に、各条件下での自己位置推定の軌跡を示す。

\begin{figure}[H]
  \centering
  \begin{tabular}{ccc}
    \begin{minipage}{0.32\textwidth}
      \centering
      \includegraphics[width=\linewidth]{figures/5/pc.png}
    \end{minipage} &
    \begin{minipage}{0.32\textwidth}
      \centering
      \includegraphics[width=\linewidth]{figures/5/ar.png}
    \end{minipage} &
    \begin{minipage}{0.32\textwidth}
      \centering
      \includegraphics[width=\linewidth]{figures/5/arpc.png}
    \end{minipage}\\
    (a) 提案手法のみ & (b) VIOのみ & (c) VIO+提案手法
  \end{tabular}
  \caption{自己位置推定軌跡の比較}
  \label{five:thirteen}
\end{figure}

\subsubsection*{画像マッチング単独の結果}
図\ref{five:thirteen}(a)に示すように、画像マッチングのみを用いた場合、
推定に成功した地点では高精度な絶対位置が得られている。しかし、軌跡は他の結果と比べて断続的になっている。
これは、以下の2点の要因によるものである。
第一に、画像データのサーバーへの送信、計算処理、そして結果の受信を含む一連の処理に平均して約0.5秒の遅延が生じ、
歩行者の移動速度に対して自己位置の更新が追いついていないためである。
第二に、移動中に生じる手ブレや、壁面の特徴点が少ない区間においてマッチング数が不足し、解が得られないフレームが発生したためである。
結果として、ナビゲーションに必要なリアルタイム性が確保できず、ユーザーへの経路提示が遅れる場面が散見された。

\subsubsection*{VIO単独の結果}
図\ref{five:thirteen}(b)に示すVIO単独の結果では、連続した軌跡が得られており、短時間であれば歩行経路を正確に追従している。
しかし、移動距離が長くなるにつれて、累積誤差により推定位置が真値から徐々に乖離していくドリフト現象が確認された。
本実験環境のように、白壁などの特徴に乏しい平面が多く存在する環境では、VIOが追跡すべき安定した特徴点が不足しやすく、スケーリングや回転角に微小な誤差が蓄積しやすい。
特に、実験の後半では推定位置が真値から数メートル以上乖離しており、VIO単独での長距離ナビゲーションには限界があることが示された。

\subsubsection*{併用手法の結果}
図\ref{five:thirteen}(c)に示す提案手法の結果では、VIOの滑らかさと画像マッチングの絶対位置精度の双方が活かされていることが確認できる。
本手法では、VIOが継続的に相対移動量を推定することで、画像マッチングの通信遅延や計算失敗による推定に失敗した区間を埋め、
途切れることのないスムーズなナビゲーションを実現した。
特筆すべきは、VIOの推定情報を、外れ値除去に活用できた点である。
\ref{localization}節で示したように、画像マッチング単独では、撮影条件によっては遠く離れた地点や誤った視点から推定するリスクがある。
しかし、提案手法では直前のVIO推定位置から大きく離れた解を即座に棄却することで、突発的な位置飛びを防ぐことに成功した。
一方で、VIOに蓄積するドリフト誤差については、定期的に得られる高精度な画像マッチング結果によって補正されるため、長時間歩行しても誤差が増大していないことが確認された。

以上の結果より、提案手法は屋内ナビゲーションにおいて不可欠なリアルタイム性と安定性を両立しており、
実用的な手法であることが実証された。