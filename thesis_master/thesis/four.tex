\chapter{入力画像とテクスチャの特徴点マッチング}

\section{特徴点検出およびマッチングの概要}

本研究では、自己位置推定を行うために、前節までに生成した簡易モデルのテクスチャ画像と入力画像との対応付けを行う。
具体的には、画像間で対応する特徴点を検出し、それらの対応関係を用いて、入力画像上の2次元特徴点と、3次元モデルに対応付けられたテクスチャ上の点との対応を構築することで、カメラの位置および姿勢を推定する。
なお、本研究で使用するテクスチャは側面テクスチャに限定する。
床面は同一テクスチャが連続して用いられることが多く、特徴点の識別が困難であるため、対応付けの対象から除外する。

この対応付けを実現するため、本章では特徴点検出および特徴点マッチングの処理を行う。
特徴点検出およびマッチング手法は、大きく従来手法と学習ベース手法の二つに分類される。
従来手法は、画像の輝度勾配や局所構造に基づいて特徴点および記述子を設計する手法であり、計算過程が明確であるという利点を持つ。
一方で、撮影条件や環境の変化に対する適応性には限界がある。
これに対して、学習ベース手法は、深層学習を用いて特徴点検出やマッチングの過程をデータから学習する手法である。
画像全体の文脈情報を考慮した対応付けが可能であり、テクスチャの少ない環境においても比較的安定した対応が得られる。
その一方で、従来手法と比較して計算コストが大きいという特徴がある。


\section{従来手法による特徴点マッチング}
\subsection{特徴点検出}
本研究では、代表的な局所特徴点検出手法として SIFT および AKAZE を用いる。
SIFT は、ガウシアン平滑化により構築されるスケール空間上で極値点を検出し、スケールおよび回転に対して不変な特徴点を得る手法である\cite{Lowe2004}。
各特徴点に対しては、周囲の勾配分布に基づく特徴量が計算され、高い識別性能を持つ。
AKAZE は、非線形スケール空間に基づいて特徴点を検出する手法であり、Fast Explicit Diffusion を用いることで高速な処理を可能としている\cite{Alcantarilla2013}。
記述子にはバイナリ表現が用いられ、後段のマッチング処理を効率的に行うことができる。
本研究では、入力画像および簡易モデルに対応するテクスチャ画像をグレースケール化した後、それぞれに対して特徴点検出および記述子計算を行う。
また、データベースとなるテクスチャ画像に対しては、特徴点を事前に計算しておくことで、マッチング時の計算負荷を低減している。

\subsection{特徴点マッチング} 
従来手法では、最近傍探索に基づくマッチング手法を採用する。
記述子間の距離を計算し、最も距離の近い特徴点同士を対応点として選択することで、初期的な対応点集合を得る。
SIFT のような実数値記述子に対しては KD-tree を用いた探索を行い、AKAZE のようなバイナリ記述子に対しては LSH を用いた探索を行うことで、
記述子の特性に応じた最近傍探索を実現している。

\subsection{マッチングの精度向上}
最近傍探索によって得られる対応点集合には、特徴量の類似度のみでは除去できない誤対応が含まれる可能性がある。  
そこで本研究では、複数の手法を組み合わせることで、マッチング精度の向上を図る。
まず、Lowe の比率テストを適用し、第一近傍と第二近傍の距離比が一定以下となる対応点のみを採用することで、曖昧な対応を除去する。
その後、RANSAC を用いて幾何的整合性に基づく外れ値除去を行う。対応点集合から射影変換モデルを推定し、モデルに適合しない対応点を除外することで、幾何的に整合した対応点集合を得る。
これらの処理により、自己位置推定に用いる対応点の精度を向上させ、後段の位置および姿勢推定における安定性の確保を図る。

\section{学習ベース手法による特徴点マッチング}
\subsection{特徴点検出}
学習ベース手法における特徴点検出手法として SuperPoint を用いる。
SuperPoint は、画像中の特徴点（Interest Point）とそれらに対応する記述子（Descriptor）を同時に推定する特徴点検出手法である（図\ref{four:one}）。
画像全体を入力とする畳み込み型ネットワークとして構成されており、共有されたエンコーダによって特徴を抽出した後、特徴点検出用と記述子生成用の2つのデコーダに分岐することで、単一のフォワードパスで両者を出力する。
この構成により、検出と記述を個別に行う手法と異なり、両タスク間で計算および特徴表現を効率的に共有することが可能となっている\cite{DeTone2018SuperPoint}。
従来手法では、輝度勾配や局所構造といった人手設計された指標に基づいて特徴点検出が行われるのに対し、大量の画像データを用いた学習による安定した特徴点検出が可能である。

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{figures/4/superpoint_architecture.png}
    \caption{SuperPointのアーキテクチャ. 出典：DeTone et al.(2018)\cite{DeTone2018SuperPoint} Fig.~1}
    \label{four:one}
  \end{center}
\end{figure}

本研究では、入力画像および簡易モデルに対応するテクスチャ画像をグレースケール化し、SuperPoint に入力することで特徴点検出および記述子計算を行う。
画像サイズが大きい場合には画像を複数のタイルに分割し、それぞれに対して特徴点検出を行った後、
検出結果を統合することで、画像全体の特徴点を抽出している。

\subsection{特徴点マッチング} 
学習ベース手法における特徴点マッチング手法として SuperGlue を用いる。
SuperGlue は、注意機構付きグラフニューラルネットワークと最適マッチング層の2つから構成される特徴点マッチング手法である（図\ref{four:two}）。
注意機構付きグラフニューラルネットワークでは、キーポイントの位置と記述子を統合した特徴表現を自己注意および相互注意を交互に用いて段階的に更新する。
最適マッチング層では、キーポイント間のスコア行列にdustbin（いずれのキーポイントとも対応しない点を扱うための仮想ノード）を追加した上で、
Sinkhorn アルゴリズムにより最適な部分対応を推定する\cite{Sarlin2020SuperGlue}。
従来手法では、各特徴点を独立に対応付ける最近傍探索が行われるのに対し、特徴点集合全体の文脈情報を考慮した対応付けが可能である。

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figures/4/superglue_architecture.png}
    \caption{SuperGlueのアーキテクチャ. 出典：Sarlin et al.(2020)\cite{Sarlin2020SuperGlue} Fig.~3}
    \label{four:two}
  \end{center}
\end{figure}

\subsection{マッチングの精度向上}
SuperGlue により得られた対応点集合には、学習に基づく推定結果であるため、局所的に信頼度の低い対応点が含まれる可能性がある。
まず、従来手法における ratio test に相当する処理として、SuperGlue の matching score に基づく対応点の選別を行う。
matching score は，各特徴点対が正しく対応している可能性の高さを表す指標であり、スコアが所定の閾値以上となる対応点のみを採用することで、曖昧な対応を除去する。
そのあとは同様に、RANSAC を用いて外れ値除去を行う。これにより、学習ベース手法においても従来手法と同等の基準で誤対応を抑制し、自己位置推定に用いる対応点の精度を向上させる。