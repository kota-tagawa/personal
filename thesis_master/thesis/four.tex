\chapter{入力画像とテクスチャの特徴点マッチング}

\section{特徴点検出およびマッチングの概要}
本研究では、自己位置推定を行うために、前節までに生成した簡易モデルのテクスチャ画像と、入力画像との対応付けを行う。  
具体的には、画像間で対応する特徴点を検出し、それらの対応関係を用いて、2次元画像上の点と、3次元モデルに対応付けられたテクスチャ上の点との対応を構築することで、カメラの位置および姿勢を推定する。  
なお、使用するテクスチャは側面テクスチャ（四角形メッシュ）のみである。床面は基本的に同じテクスチャが連続して使いづらいため
この対応付けを実現するために、本章では特徴点検出および特徴点マッチングの処理を行う。  
特徴点検出では、画像中から局所的に識別性の高い点を抽出し、特徴点マッチングでは、異なる画像間で同一物体に対応する特徴点同士を対応付ける。

特徴点検出およびマッチング手法は、大きく従来手法と学習ベース手法の二つに分類される。  
従来手法は、画像の輝度勾配や局所構造に基づいて特徴点および記述子を設計する手法であり、計算過程が明確であるという利点を持つ。一方で、環境や撮影条件の変化に対する適応性には限界がある。  
これに対して、学習ベース手法は、深層学習を用いて特徴点検出やマッチングの過程をデータから学習する手法である。画像全体の文脈情報を考慮した対応付けが可能であり、
テクスチャの少ない環境においても安定した対応が得られる反面、従来手法と比較して計算コストが大きいという特徴がある。
従来手法と学習ベース手法の両方を用い、それぞれの実行時間および自己位置推定精度を比較することで、有効性を評価する

それぞれの手法における特徴点マッチング処理の流れを図1に示す。各処理の理論的背景および詳細については、以下の節で説明する。


\section{従来手法による特徴点マッチング}
\subsection{特徴点検出}
本研究では、代表的な局所特徴点検出手法として SIFT および AKAZE を用いる。
SIFT は、ガウシアン平滑化により構築されるスケール空間上で極値点を検出し、スケールおよび回転に対して不変な特徴点を得る手法である\cite{Lowe2004}。
各特徴点に対しては、周囲の勾配分布に基づく特徴量が計算され、高い識別性能を持つ。
AKAZE は、非線形スケール空間に基づいて特徴点を検出する手法であり、Fast Explicit Diffusion を用いることで高速な処理を可能としている\cite{Alcantarilla2013}。
記述子にはバイナリ表現が用いられ、後段のマッチング処理を効率的に行うことができる。
本研究では、入力画像および簡易モデルに対応するテクスチャ画像をグレースケール化した後、それぞれに対して特徴点検出および記述子計算を行う。
また、データベースとなるテクスチャ画像に対しては、特徴点を事前に計算しておくことで、マッチング時の計算負荷を低減している。

\subsection{特徴点マッチング} 
従来手法では、最近傍探索に基づくマッチング手法を採用する。
記述子間の距離を計算し、最も距離の近い特徴点同士を対応点として選択することで、初期的な対応点集合を得る。
SIFT のような実数値記述子に対しては KD-tree を用いた探索を行い、AKAZE のようなバイナリ記述子に対しては LSH を用いた探索を行うことで、
記述子の特性に応じた最近傍探索を実現している。

\subsection{マッチングの精度向上}
最近傍探索によって得られる対応点集合には、特徴量の類似度のみでは除去できない誤対応が含まれる可能性がある。  
そこで本研究では、複数の手法を組み合わせることで、マッチング精度の向上を図る。
まず、Lowe の比率テストを適用し、第一近傍と第二近傍の距離比が一定以下となる対応点のみを採用することで、曖昧な対応を除去する。
その後、RANSAC を用いて幾何的整合性に基づく外れ値除去を行う。対応点集合から射影変換モデルを推定し、モデルに適合しない対応点を除外することで、幾何的に整合した対応点集合を得る。
これらの処理により、自己位置推定に用いる対応点の精度を向上させ、後段の位置および姿勢推定における安定性の確保を図る。

\section{学習ベース手法による特徴点マッチング}
\subsection{特徴点検出}
学習ベース手法における特徴点検出手法として SuperPoint を用いる。
SuperPoint は畳み込みニューラルネットワークを用いて、画像中の特徴点位置と対応する記述子を同時に推定する手法である\cite{DeTone2018SuperPoint}。
従来手法では、輝度勾配や局所構造といった人手設計された指標に基づいて，特徴点検出および記述子生成が行われるのに対し、
大量の画像データを用いた学習による安定した特徴点検出が可能である。

本研究では、入力画像および簡易モデルに対応するテクスチャ画像をグレースケール化し、SuperPoint に入力することで特徴点検出および記述子計算を行う。
画像サイズが大きい場合には画像を複数のタイルに分割し、それぞれに対して特徴点検出を行った後、
検出結果を統合することで、画像全体の特徴点を抽出している。

\subsection{特徴点マッチング} 
学習ベース手法における特徴点マッチング手法として SuperGlue を用いる。
SuperGlue は特徴点集合をグラフ構造として扱い、自己注意機構を用いて特徴点間の対応関係を推定する学習ベースのマッチング手法である\cite{Sarlin2020SuperGlue}。
従来手法では、各特徴点を独立に対応付ける最近傍探索が行われるのに対し、特徴点集合全体の文脈情報を考慮した対応付けが可能である。

\subsection{マッチングの精度向上}
SuperGlue により得られた対応点集合には、学習に基づく推定結果であるため、局所的に信頼度の低い対応点が含まれる可能性がある。
まず、従来手法における ratio test に相当する処理として、SuperGlue の matching score に基づく対応点の選別を行う。
matching score は，各特徴点対が正しく対応している可能性の高さを表す指標であり、スコアが所定の閾値以上となる対応点のみを採用することで、曖昧な対応を除去する。
そのあとは同様に、RANSAC を用いて外れ値除去を行う。これにより、学習ベース手法においても従来手法と同等の基準で誤対応を抑制し、自己位置推定に用いる対応点の精度を向上させる。