\chapter{自己位置推定結果を用いた屋内ナビゲーション}


\section{屋内ナビゲーションの方針}

\subsection{簡易モデルによる自己位置推定の課題}

実際のカメラ入力を用いてリアルタイムに動作させる場合、特徴点マッチング処理に伴う計算コストや通信遅延により、
推定位置の更新が滞り、端末の実際の位置と乖離する可能性がある。
さらに、屋内環境では特徴の乏しい壁面や照明変化の影響により、常に十分な特徴量が得られるとは限らず、
マッチングに失敗して自己位置が更新されない状況も想定される。
また、屋内ナビゲーションでは利用者がモバイル端末を持って移動するため、自己位置推定には高いリアルタイム性と連続性が求められるが、
特徴点マッチング単独ではこれらを常に保証することが困難である。

\subsection{提案手法に基づく屋内ナビゲーションの基本方針}

本研究では、特徴点マッチングに基づく自己位置推定結果を用いて、屋内空間におけるナビゲーションを実現することを目的とする。
推定した自己位置情報は、ユーザに対して進行方向や目的地までの誘導情報を提示するために用いられる。

しかしながら、前述の通り特徴点マッチングに基づく手法は計算コストが高く、リアルタイム性や安定性の観点から単独での利用には課題がある。
そのため、本研究では提案する自己位置推定手法をナビゲーションの絶対的な位置補正の基準情報として用いつつ、
自己位置推定間の移動量推定には別の補間手段を導入する方針とする。
具体的には、モバイル端末に標準的に搭載されている VIO (Visual-Inertial Odometry) による自己位置推定結果を併用する。
VIOにより高頻度かつ連続的な位置追跡を行い、特徴点マッチングに失敗した場合や推定結果が得られない期間においても、ナビゲーションの連続性を維持する。

\subsection{Visual-Inertial Odometry (VIO) による自己位置推定}

Visual-Inertial Odometry (VIO) は、端末に搭載されたIMU（加速度計、ジャイロスコープ等の慣性センサ）と
カメラから取得した画像情報を統合することで、端末の位置姿勢を高頻度に推定する手法である。
本研究では、Apple社が提供するARKitをVIOの実行環境として用いる\cite{AppleARKitTracking}。
ARKitは、このVIO技術を中核とした自己位置推定フレームワークであり、内部処理において局所的な特徴点マップを構築することで、
モバイル端末単体での SLAM (Simultaneous Localization and Mapping) に相当する機能を実現している。
ARKitによる自己位置推定は、端末内のみで処理されるため外部インフラを必要とせず、高いリアルタイム性が確保される。
一方で、長時間動作させた際の累積誤差（ドリフト）や、白い壁のみが映る場合などカメラ視野が環境特徴に乏しい状況では、
推定精度が低下する可能性がある点に注意が必要である\cite{AppleARKitWorldTracking}。

ARKitでは、ワールド座標系が内部的に定義されており、セッション初期化時の端末位置が原点として設定される。
座標軸は右手系で定義されており、一般に重力と反対方向を$Y$軸とし、
初期化時のカメラの視線方向に基づいて$Z$軸および$X$軸が決定される。
以降のフレームにおける端末の位置姿勢は、このワールド座標系に対する相対的な変換行列として逐次更新される。

\subsection{ARKitの座標系の定義}
本研究では、ARKitによって定義されるワールド座標系をAR座標系と呼ぶ。
ここで、ユーザが定義する世界座標系を含めた各座標系の関係を図\ref{four:one}に示す。

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.7\textwidth]{figures/4/axis2.png}
    \caption{世界座標系とARKitカメラ座標系、AR座標系の関係}
    \label{four:one}
  \end{center}
\end{figure}

ここで注意すべき点は、カメラ座標系の軸の符号定義が異なることである。
OpenCVにおけるカメラ座標系では、$X$軸は右方向、$Y$軸は下方向、$Z$軸は奥行き方向が正となる。
一方、ARKitにおけるカメラ座標系では、$X$軸は右方向、$Y$軸は上方向、$Z$軸は手前方向が正となる。
ARKitのカメラ座標 $\bm{X}_{\mathrm{camAR}}$ と、本研究で用いるOpenCVのカメラ座標 $\bm{X}_{\mathrm{camPC}}$ の関係は、
変換行列 $\bm{S}$ を用いて次式で表される。

\begin{align}
  \bm{X}_{\mathrm{camPC}}
  = \bm{S} \, \bm{X}_{\mathrm{camAR}}
  , \quad
  \bm{S}
  =
  \begin{bmatrix}
  1 & 0 & 0 \\
  0 & -1 & 0 \\
  0 & 0 & -1
  \end{bmatrix}
  \label{eq:camtransform}
\end{align}

\section{自己位置推定手法の比較検討方針}

本研究では、屋内ナビゲーションにおける実用的な自己位置推定手法を明らかにするため、
性質の異なる3つの手法を比較対象として設定した。
これらは、提案手法単独の場合、既存のモバイル端末における標準的手法の場合、
および両者を組み合わせた場合をそれぞれ代表するものである。

\begin{enumerate}
  \item \textbf{提案手法（特徴点マッチングによる自己位置推定）} \\
        本研究の提案内容そのものの性能を評価するための基準として位置付ける。
        環境モデルとの対応付けに基づいて絶対的な自己位置推定が可能である一方、計算時間や誤推定が課題となる可能性がある。
  \item \textbf{ARKitによる自己位置推定} \\
        モバイル端末上で動作する一般的な自己位置推定手法として位置付ける。
        リアルタイム性に優れている一方、視覚情報に乏しい環境では精度が低下する可能性がある。
  \item \textbf{複合的手法（提案手法 + ARKit）} \\
        提案手法を基準情報として用いつつ、推定が困難な状況では ARKit の推定結果を利用する方式である。
        これにより、両者の利点を活かしたより安定的かつ実用的な自己位置推定の可能性を検討する。
\end{enumerate}

以上の3つの手法を比較することで、屋内ナビゲーションにおける実用的な自己位置推定手法の在り方について検証する。


\section{屋内ナビゲーションシステムの構成}

屋内ナビゲーションシステムの構成について説明する。システムの流れを図\ref{four:three}に示す。

本システムは、ユーザインターフェースおよびセンシングを担うモバイル端末と、
高負荷な自己位置推定処理を担うPCサーバによって構成される。

処理の全体的な流れは以下の通りである。
まず、ユーザがモバイル端末上で目的地を設定すると、ナビゲーションが開始される。
モバイル端末は、取得したカメラ画像およびARKitのトラッキング情報をPCへ送信する。
PC側では、受信した画像と簡易3次元モデルを用いて特徴点マッチングを行い、世界座標系における厳密なカメラ位置姿勢を算出する。
その結果がモバイル端末へ送信されることで、AR座標系と世界座標系の間で整合性が取られ、
目的地のAR描画や、端末の自己位置のフィードバックが可能となる。以下の節で、各処理の詳細について述べる。

\begin{figure}[H]
  \centering
  \begin{tabular}{c}
      \includegraphics[width=0.9\linewidth]{figures/4/flow.png}
  \end{tabular}
  \caption{屋内ナビゲーションシステムの構成}
  \label{four:three}
\end{figure}

\subsection{目的地設定}

マップ画像上でのタップ操作により目的地を指定する方法を用いる。
ユーザは表示されたマップ画像上を順にタップすることで、目的地までの経路点を指定する。
各タップ位置は、マップ上の画像座標として取得される。入力が確定すると、あらかじめ算出したマップ上の画像座標と世界座標を対応付けるホモグラフィ行列を用いて、世界座標系へ変換する。
変換後の世界座標列は、後続の自己位置推定およびナビゲーション処理における目的地情報として利用する。

\subsection{カメラ画像取得および端末とPC間の通信}

端末側では、カメラ画像と撮影時刻を取得し、初期位置推定時は、カメラの内部パラメータも併せて取得する。
また、撮影時におけるAR座標系とカメラ座標系の変換行列を保存する。
取得したカメラ画像は、通信負荷を低減するために圧縮処理を行う。
2回目以降の推定では、ARKitにより更新されたカメラの位置姿勢情報も用い、これらをJSON形式にまとめ、WebSocketを用いた双方向通信によってPCへ送信する。

PCで推定されたカメラの位置姿勢情報は、同じくWebSocketを介して端末側へ送信され、世界座標系とAR座標系の関係の更新に用いられる。
なお、一定時間以上姿勢情報が受信されない場合には、自己位置が喪失したものと判断し、初期位置推定を再度実行する。

\subsection{自己位置推定結果の受信および座標系の更新}

端末側では、PCで推定された世界座標系とカメラ座標系の変換行列を受信する。
受信した世界座標系とカメラ座標系の回転行列 $\bm{R}_{\mathrm{world}\rightarrow\mathrm{camPC}}$
および並進ベクトル $\bm{t}_{\mathrm{world}\rightarrow\mathrm{camPC}}$ と、
撮影時におけるAR座標系とカメラ座標系の変換行列 $\bm{T}_{\mathrm{camAR}\rightarrow\mathrm{AR}}$
を用いて、世界座標系とAR座標系の変換行列を更新する。
これにより、世界座標系とAR座標系の相互変換が可能となり、PCによる自己位置推定が困難なタイミングにおいても、ARKitによる自己位置推定結果を継続的に利用できる。
更新された座標系の関係は、目的地のARオブジェクトの描画や、カメラの位置姿勢を世界座標系へ変換する際に用いられる。
変換行列を更新した後、一定時間経過後に再度カメラ画像を取得し、PCによる自己位置推定を行う。

\subsection{世界座標系とAR座標系の相互変換}

本システムにおいて、ARKitによって管理されるAR座標系と、簡易モデルが定義されている世界座標系は、原点および座標軸の定義が異なる。
そのため、以下の2つの目的を実現するには、両座標系間の相互変換が必要となる。

\begin{enumerate}
  \item \textbf{世界座標系からAR座標系の変換} \\
  世界座標系で定義された目的地を、モバイル端末のカメラ映像上の正しい位置に重畳表示するためには、
  目的地の座標をAR座標系へ変換する必要がある。

  \item \textbf{AR座標系から世界座標系の変換} \\
  ARKitによって高頻度に追跡される端末の位置姿勢をPCへ送信し、特徴点マッチングによる自己位置推定結果と比較するためには、
  端末の位置姿勢を世界座標系へ変換する必要がある。
\end{enumerate}

以下に、これらの変換を実現するための行列の導出過程を示す。

ARKitでは、毎フレームカメラ変換行列 $\bm{T}_{\mathrm{camAR}\rightarrow\mathrm{AR}}$ が与えられる。
これはARKitのカメラ座標系からAR座標系への変換を表す $4\times{4}$ の同次変換行列であり、次式で定義される。
\begin{equation}
  \bm{T}_{\mathrm{camAR}\rightarrow\mathrm{AR}} =
  \begin{pmatrix}
  \bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}} & \bm{t}_{\mathrm{camAR}\rightarrow\mathrm{AR}} \\
  \bm{0}^{\top} & 1
  \end{pmatrix}
\end{equation}
ここで、$\bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}$ はARKitのカメラ座標系からAR座標系への回転行列、
$\bm{t}_{\mathrm{camAR}\rightarrow\mathrm{AR}}$ はAR座標系におけるカメラ中心位置を表す並進ベクトルである。

よって、AR座標系における座標 $\bm{X}_{\mathrm{AR}}$ は、ARKitのカメラ座標 $\bm{X}_{\mathrm{camAR}}$ から式(\ref{eq:one})で求められる。
\begin{equation}
  \bm{X}_{\mathrm{AR}}
  =
  \bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \bm{X}_{\mathrm{camAR}}
  +
  \bm{t}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \label{eq:one}
\end{equation}

一方、世界座標系における座標 $\bm{X}_{\mathrm{world}}$ は、OpenCVのカメラ座標 $\bm{X}_{\mathrm{camPC}}$ から式(\ref{eq:two})で求められる。
\begin{equation}
  \bm{X}_{\mathrm{camPC}}
  =
  \bm{R}_{\mathrm{world}\rightarrow\mathrm{camPC}}
  \bm{X}_{\mathrm{world}}
  +
  \bm{t}_{\mathrm{world}\rightarrow\mathrm{camPC}}
  \label{eq:two}
\end{equation}

ここで、式(\ref{eq:camtransform})で示した通り、
ARKitのカメラ座標系とOpenCVのカメラ座標系には軸定義の違いによる変換行列 $\bm{S}$ が介在する。
式(\ref{eq:two})および式(\ref{eq:camtransform})を式(\ref{eq:one})に代入することで、世界座標系からAR座標系への変換は次のように整理される。
\begin{align}
  \bm{X}_{\mathrm{AR}}
  &=
  \bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \left(
    \bm{S} \bm{X}_{\mathrm{camPC}}
  \right)
  +
  \bm{t}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \\
  &=
  \bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \left(
    \bm{S} (
      \bm{R}_{\mathrm{world}\rightarrow\mathrm{camPC}}
      \bm{X}_{\mathrm{world}}
      +
      \bm{t}_{\mathrm{world}\rightarrow\mathrm{camPC}}
    )
  \right)
  +
  \bm{t}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \\
  &=
  (\bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \bm{S}
  \bm{R}_{\mathrm{world}\rightarrow\mathrm{camPC}})
  \bm{X}_{\mathrm{world}}
  +
  (\bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \bm{S}
  \bm{t}_{\mathrm{world}\rightarrow\mathrm{camPC}}
  +
  \bm{t}_{\mathrm{camAR}\rightarrow\mathrm{AR}})
\end{align}

したがって、世界座標系からAR座標系への変換行列 $\bm{R}_{\mathrm{world}\rightarrow\mathrm{AR}}, \bm{t}_{\mathrm{world}\rightarrow\mathrm{AR}}$ は次式で求められる。
\begin{align}
  \bm{R}_{\mathrm{world}\rightarrow\mathrm{AR}}
  &=
  \bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \bm{S}
  \bm{R}_{\mathrm{world}\rightarrow\mathrm{camPC}}
  \\
  \bm{t}_{\mathrm{world}\rightarrow\mathrm{AR}}
  &=
  \bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \bm{S}
  \bm{t}_{\mathrm{world}\rightarrow\mathrm{camPC}}
  +
  \bm{t}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \label{eq:four}
\end{align}

逆に、AR座標系から世界座標系への変換行列 $\bm{R}_{\mathrm{AR}\rightarrow\mathrm{world}}, \bm{t}_{\mathrm{AR}\rightarrow\mathrm{world}}$ は、式(\ref{eq:four})の逆変換として次式で導出される。
\begin{align}
  \bm{X}_{\mathrm{world}}
  &=
  \bm{R}_{\mathrm{world}\rightarrow\mathrm{AR}}^{\top}
  \bm{X}_{\mathrm{AR}}
  -
  \bm{R}_{\mathrm{world}\rightarrow\mathrm{AR}}^{\top}
  \bm{t}_{\mathrm{world}\rightarrow\mathrm{AR}}
  \\
  &=
  \bm{R}_{\mathrm{AR}\rightarrow\mathrm{world}}\bm{X}_{\mathrm{AR}}
  +
  \bm{t}_{\mathrm{AR}\rightarrow\mathrm{world}}
\end{align}
ここで、各項は以下の通りである。
\begin{align}
  \bm{R}_{\mathrm{AR}\rightarrow\mathrm{world}}
  &=
  \bm{R}_{\mathrm{world}\rightarrow\mathrm{AR}}^{\top} \nonumber
  \\
  &=
  (\bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \bm{S}
  \bm{R}_{\mathrm{world}\rightarrow\mathrm{camPC}}
  )^{\top}
  \\
  \bm{t}_{\mathrm{AR}\rightarrow\mathrm{world}}
  &=
  -
  \bm{R}_{\mathrm{world}\rightarrow\mathrm{AR}}^{\top}
  \bm{t}_{\mathrm{world}\rightarrow\mathrm{AR}} \nonumber
  \\
  &=
  -
  \bm{R}_{\mathrm{AR}\rightarrow\mathrm{world}}
  (
  \bm{R}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  \bm{S}
  \bm{t}_{\mathrm{world}\rightarrow\mathrm{camPC}}
  +
  \bm{t}_{\mathrm{camAR}\rightarrow\mathrm{AR}}
  )
  \label{eq:five}
\end{align}

\subsection{目的地および進行方向オブジェクトの描画}
更新された世界座標系とAR座標系の関係に基づき、目的地および進行方向を示すARオブジェクトの描画を行う。
まず、マップから取得した経路上の目的地座標を世界座標系で取得し、
前節で求めた変換式を用いてAR座標系への変換を行うことで、AR空間上における目的地の描画位置を算出する。

算出されたAR座標系上の位置に対してARアンカーを生成する。
ARアンカーは、AR空間中の特定位置に仮想オブジェクトを安定して配置するための基準点として用いられ、端末の移動にかかわらず一貫した位置関係を保つ役割を持つ。
生成したアンカーに目的地を示すオブジェクトを紐付けることで、目的地をカメラ映像上の正しい位置に重畳表示する。
目的地が更新された場合には、既存のアンカーを削除し、新たな座標に基づいてアンカーを再生成する。

また、各フレームにおいてカメラの位置姿勢を取得し、カメラ前方に進行方向を示す矢印オブジェクトを配置する。
矢印オブジェクトが目的地の方向を向くように姿勢を更新することで、ユーザに対して目的地までの直感的な誘導を実現する。
さらに、カメラの位置および視線ベクトルを毎フレーム更新することで、自己位置推定結果を継続的に利用可能とし、
PCによる自己位置推定結果が適切であるかを判断するための指標としても用いることができる。

カメラ位置と目的地オブジェクトとの距離を算出し、一定の閾値以内に到達した場合には、目的地に到着したと判定する。
経路上に複数の目的地が存在する場合には、次の目的地へ切り替え、対応するARオブジェクトの更新を行う。