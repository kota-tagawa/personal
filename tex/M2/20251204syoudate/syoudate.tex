\documentclass[]{jarticle}          % 一段組
%\documentclass[twocolumn]{jarticle} % 二段組

\textwidth 180mm
\textheight 255mm
\oddsidemargin -12mm
\topmargin -15mm
\columnsep 10mm

%\vspace{0.5cm} % 一段組の場合はコメントアウトした方が体裁がよいx
%] % 一段組の場合はコメントアウトする

\usepackage{styles/labheadings}
\usepackage[dvipdfmx]{graphicx,color}
\usepackage{amsmath,amssymb}
\usepackage{url}
% 追加
\usepackage[hang,small,bf]{caption}
\usepackage[subrefformat=parens]{subcaption}
\usepackage{float}
\captionsetup{compatibility=false}

\input{numerical_definition.tex}
% report.texと同じディレクトリにnumerical_definition.texを入れておけば上の書き方でもいいはずです

\usepackage[
  dvipdfm,
  bookmarks=true,
  bookmarksnumbered=true,
  colorlinks=true]{hyperref}
\AtBeginDvi{\special{pdf:tounicode EUC-UCS2}}

\pagestyle{labheadings}
\headerleft{修士論文ー章立てー}   % ヘッダの左側のタイトル
\headerright{2025年1月22日}  % ヘッダの右側のタイトル

\begin{document}

%\twocolumn % 一段組の場合はコメントアウトする

\vspace*{2ex}
\begin{center}
 {\Large \bf ワイヤーフレームと全方位画像による簡易モデルを用いた屋内環境での自己位置推定}\\ % タイトル
 \vspace*{5mm}
 {\large M2 田川幸汰}% 発表者名
\end{center}

%\vspace{0.5cm} % 一段組の場合はコメントアウトした方が体裁がよいx
%] % 一段組の場合はコメントアウトする

%新しく作成したコマンド
% \newcommand{\reffig}[1]{\hyperref[#1]{図\ref{#1}}}
% \newcommand{\refeq}[1]{\hyperref[#1]{式(\ref{#1})}}
% \newcommand{\reftab}[1]{\hyperref[#1]{表\ref{#1}}}
% \newcommand{\refsec}[1]{\hyperref[#1]{\ref{#1}章}}
% \newcommand{\refsubsec}[1]{\hyperref[#1]{\ref{#1}節}}

% 数式
%\begin{equation}
%  数式記述  
%  \label{ラベル名}
%\end{equation}

% 図
% \begin{figure}[!ht]
%   \begin{center}
%     \includegraphics[scale=0.5]{figures/画像ファイル名}
%     \caption{キャプション名}
%     \label{ラベル名}
%   \end{center}
% \end{figure}

% リスト
% \begin{enumerate or itemize}
%   \item 
% \end{enumerate or itemize}
\section{はじめに}
\subsection{研究背景}
デジタルツイン市場は急速に拡大しており、現実空間とデジタル空間をリアルタイムに連携させるためには高精度な自己位置推定技術が不可欠である。
屋内で用いられる主な手法として、SLAMはLiDARやカメラを用いて高精度な位置推定と地図生成が可能であるが、専用機材や高性能なハードウェアを要求する。
一方、無線測位は追加機材を設置することで屋内測位が可能となるものの、専用タグやビーコンの設置が必要であり、運用負担の大きさが導入の障壁となっている。
そのため、既存環境を大きく変更することなく、低コストで実用的な精度を実現できる自己位置推定手法が求められている。

\subsection{研究目的}
本研究では、ワイヤーフレームに全方位画像から取得したテクスチャを貼り付けた簡易三次元モデルを用いた自己位置推定手法を提案する。
特別な設備やマーカーを新たに設置する必要がなく、既存の建物環境をそのまま利用できる点を特徴とする。
カメラ画像と簡易モデル上のテクスチャとの特徴点マッチングの結果を用いて自己位置を推定する。
また、推定結果の精度と処理速度が実用上有効であることを、道案内システムの実装を通じて検証する。

\subsection{本論文の構成}
本論文では、2章で簡易なテクスチャ付き3次元モデルの生成手法を示す。
3章では簡易モデルと入力画像のマッチング手法、4章ではマッチングによって得られた対応点を用いた自己位置推定手法を示す。
5章では、簡易モデルを用いた自己位置推定の実験結果について示す。
さらに6章では、自己位置推定結果を活用した道案内システムの実装と、その精度の実用性を検証する。

\section{簡易3次元モデルの作成}
本節では、簡易3次元モデルを生成する手法について説明する。
\subsection{ワイヤーフレームモデルの生成}
メッシュの頂点情報を入力として、テクスチャを割り当てていない状態のモデルを生成する方法を説明する。
\subsection{全方位画像からの透視投影画像生成}
全方位画像座標から透視投影画像座標に変換する方法を説明する。
\subsection{透視投影画像を用いたカメラ位置姿勢推定}
複数方向の透視投影画像を用いた外部パラメータ推定方法を説明する。
\subsection{テクスチャ取得}
テクスチャ取得の方法を以下に示す。
\begin{enumerate}
  \item メッシュ頂点の世界座標を、カメラの外部パラメータを用いてカメラ座標に変換する
  \item カメラ中心とメッシュ重心の距離と角度を計算し、条件を満たすメッシュだけをテクスチャの候補にする
  \item カメラをメッシュ重心へ向けるように調整し、透視投影画像の座標に変換する
  \item テクスチャの形状を、元のメッシュ形状に射影変換する
\end{enumerate}

\section{入力画像とテクスチャの特徴点マッチング}
本節では、特徴点の検出およびマッチング手法について説明する。
\subsection{特徴点検出}
SIFT、AKAZE、SuperPointを用いた特徴点検出方法を説明する。  
SuperPointは、画像から高品質な特徴点と記述子を同時に抽出できる学習ベースの特徴点検出器である。
\subsection{特徴点マッチング}
最近傍探索やSuperGlueを用いた特徴点マッチング方法を説明する。  
SuperGlueは、特徴点間の文脈情報を考慮して高精度に対応付けを行う学習ベースのマッチング手法である。
\subsection{誤マッチ除去}
Lowe's Ratio TestやRANSACを用いて、誤マッチを除去する方法を説明する。

\section{自己位置推定}
本節では、自己位置推定手法について説明する。
\subsection{テクスチャ画像座標から世界座標への変換}
テクスチャのUV座標とメッシュ頂点の世界座標から基底ベクトルを算出し、基底ベクトルの係数を揃えることで、
テクスチャ上の2次元特徴点を3次元座標に変換する。
\subsection{自己位置推定アルゴリズム}
自己位置推定の方法を以下に示す。
\begin{enumerate}
  \item カメラ画像の2次元特徴点とテクスチャの3次元特徴点を用い、直交射影誤差の大域最適化により自己位置を推定する
  \item 幾何学的制約に基づき、天地が反転した推定候補を除外する
  \item 目的関数が最小の解を最終的な自己位置推定結果として採用する
\end{enumerate}

\section{実験}
本節では、簡易モデルを用いた自己位置推定実験に用いた機材、パラメータ、入力データ、および実験結果について説明する。
\subsection{特徴点の計測と全方位画像撮影}
C棟5階における特徴点を計測し、4m間隔で全方位画像を撮影した。
\subsection{全方位カメラパラメータ推定結果}
外部パラメータの推定結果を実測値と比較したところ、カメラ位置の誤差はおおむね10cm以下であることを確認した。
\subsection{モデル生成結果}
壁面や扉付近など特徴量が乏しい領域には、ポスターを貼付して特徴量を追加したモデルを作成し、その効果を検証した。
\subsection{特徴点マッチング結果}
学習ベースの手法は、一般的な手法と比較して特徴が乏しい画像でも比較的安定してマッチングできた。  
一方、入力画像が複数のテクスチャ画像と類似した特徴を含む場合、どちらの手法でも正しいマッチングが困難であった。
\subsection{自己位置推定結果}
動画の各フレームを抽出し、特徴点マッチングと自己位置推定を実施した。  
初回は全テクスチャとマッチングを行い、2回目以降は直前の自己位置から近傍のテクスチャに限定してマッチングを行った。  
学習ベース手法では、特徴点マッチングが行われたフレーム数が一般手法の約5倍となり、ほぼすべてのフレームで自己位置を推定できた。  
1フレームあたりの計算時間は約0.3秒であり、特徴点マッチングに時間の大部分がかかっていることが確認できた。
\subsection{目的地までの矢印描画}
フロアマップから目的地を選択し、推定した自己位置から目的地までの矢印を入力動画に描画した。  
特徴点マッチングに成功した場合、AR描画が正しく反映されることを確認した。


\section{自己位置推定結果を用いたAR道案内システム}
実際のカメラ入力を用いてリアルタイムに動作させる場合、
特徴点マッチング処理に起因する遅延により、推定位置が端末の実際の位置とずれる可能性がある。  
また、屋内環境では常に十分な特徴量が得られるとは限らず、マッチングに失敗して自己位置が更新されない状況も想定される。  
より安定した自己位置推定を実現し、実用的なAR道案内システムを構築するため、本研究ではセンサ情報との併用を検討した。  
\subsection{AR道案内システムの構成}
本節では、構築したAR道案内システムの構成について説明する。
\subsubsection{目的地設定}
画面上にマップ画像を表示し、ユーザーはタップ操作により目的地および経路上の右左折ポイントを選択できる。  
選択したポイントは、ホモグラフィー行列を用いて画像座標から世界座標に変換する。
\subsubsection{端末とPC間の通信}
WebSocketを用いて端末とPCを接続し、カメラフレーム、内部パラメータ、センサ情報に基づき更新された自己位置をPCへ送信する。  
また、PC側で計算された自己位置推定結果を非同期に受信し、目的地のAR表示および自己位置の更新に利用する。
\subsubsection{センサによる自己位置の更新と補正}
Appleが提供するAR開発フレームワークであるARKitは、センサ情報と画面上の特徴点の追跡を組み合わせて、毎フレーム端末の位置と姿勢を推定する。  
端末側では、この位置姿勢変化をもとに、PCから受信した自己位置情報と統合することで自己位置を更新する仕組みを構築している。  
現在、座標変換および統合処理は実装中である。
\subsubsection{ARオブジェクト描画処理}
目的地を示すピンオブジェクトと、現在位置から目的地方向を指し示す矢印オブジェクトをAR空間に描画する。
\subsection{動作結果と評価}
本システムは現在実装途中であり、センサ情報に基づく自己位置更新処理は未完成である。  
センサのみを用いた位置推定では推定誤差が蓄積することから、PCから正確な自己位置推定結果が得られたタイミングで姿勢・位置をリセットする仕組みを導入することが望ましい。

\section{まとめ}
本節では、本研究の成果と今後の展望について述べる。
\subsection{本研究の成果}
本研究では、簡易モデルを用いた屋内環境での自己位置推定手法を提案した。  
提案手法を用いた道案内ARアプリケーションの実装を通じて、自己位置推定結果が実用的な精度で取得できることを確認した。
\subsection{今後の展望}
今後は、AR道案内システムを完成させるとともに、Visual SLAMなど既存の自己位置推定手法と比較することで作成コストや精度を評価したい。

\end{document}
